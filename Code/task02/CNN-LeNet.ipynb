{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN卷积神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 二维互相关运算\n",
    "\n",
    "#### 虽然卷积层得名于卷积（convolution）运算，但我们通常在卷积层中使用更加直观的互相关（cross-correlation）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def corr2d(X, K):\n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros((X.shape[0] - h + 1), (X.shape[1] - w + 1)) \n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j] = (X[i:i+h, j:j+w] * K).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 二维卷积层\n",
    "\n",
    "#### 二维卷积层将输入和卷积核做互相关运算，并加上一个标量偏差来得到输出。卷积层的模型参数包括了卷积核和标量偏差。在训练模型的时候，通常我们先对卷积核随机初始化，然后不断迭代卷积核和偏差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Conv2D(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super(Conv2D, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(kernel_size), requires_grad = True)\n",
    "        self.bias = nn.Parameter(torch.randn(1), requires_grad = True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return corr2d(x, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3通过数据学习核数组\n",
    "\n",
    "#### 使用物体边缘检测中的输入数据X和输出数据Y来学习我们构造的核数组K。我们首先构造一个卷积层，其卷积核将被初始化成随机数组。接下来在每一次迭代中，我们使用平方误差来比较Y和卷积层的输出，然后计算梯度来更新权重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 0., 0., 0., 1., 1.]])\n",
      "tensor([[ 1.0000e+03, -1.0000e-01]])\n",
      "tensor([[ 9.9990e+02,  1.0000e+03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -1.0000e-01,  9.9990e+02],\n",
      "        [ 9.9990e+02,  1.0000e+03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -1.0000e-01,  9.9990e+02],\n",
      "        [ 9.9990e+02,  1.0000e+03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -1.0000e-01,  9.9990e+02],\n",
      "        [ 9.9990e+02,  1.0000e+03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -1.0000e-01,  9.9990e+02],\n",
      "        [ 9.9990e+02,  1.0000e+03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -1.0000e-01,  9.9990e+02],\n",
      "        [ 9.9990e+02,  1.0000e+03,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         -1.0000e-01,  9.9990e+02]])\n"
     ]
    }
   ],
   "source": [
    "X = torch.ones(6, 8)\n",
    "X[:, 2:6] = 0\n",
    "K = torch.tensor([[1000, -0.1]])\n",
    "Y = corr2d(X, K)\n",
    "print(X)\n",
    "print(K)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5, loss 1607044.750\n",
      "Step 10, loss 359850.531\n",
      "Step 15, loss 90437.742\n",
      "Step 20, loss 24095.795\n",
      "Step 25, loss 6588.963\n",
      "Step 30, loss 1821.451\n",
      "Step 35, loss 505.761\n",
      "Step 40, loss 140.686\n",
      "Step 45, loss 39.162\n",
      "Step 50, loss 10.905\n",
      "Step 55, loss 3.037\n",
      "Step 60, loss 0.846\n",
      "Step 65, loss 0.235\n",
      "Step 70, loss 0.066\n",
      "Step 75, loss 0.018\n",
      "Step 80, loss 0.005\n",
      "Step 85, loss 0.001\n",
      "Step 90, loss 0.000\n",
      "Step 95, loss 0.000\n",
      "Step 100, loss 0.000\n"
     ]
    }
   ],
   "source": [
    "conv2d = Conv2D(kernel_size = (1,2))\n",
    "\n",
    "step = 100\n",
    "lr = 0.01\n",
    "\n",
    "for i in range(step):\n",
    "    Y_hat = conv2d(X)\n",
    "    l = ((Y_hat - Y)**2).sum()\n",
    "    l.backward()\n",
    "    \n",
    "    #梯度下降\n",
    "    conv2d.weight.data -= lr * conv2d.weight.grad\n",
    "    conv2d.bias.data -= lr * conv2d.bias.grad\n",
    "    \n",
    "    #梯度清0\n",
    "    conv2d.weight.grad.fill_(0)\n",
    "    conv2d.bias.grad.fill_(0)\n",
    "    \n",
    "    if (i + 1) % 5 == 0:\n",
    "        print('Step %d, loss %.3f' % (i + 1, l.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0000e+03, -9.8594e-02]])\n",
      "tensor([-1.0499e-05])\n"
     ]
    }
   ],
   "source": [
    "print(conv2d.weight.data)\n",
    "print(conv2d.bias.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 填充和步幅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# 定义一个函数来计算卷积层。它对输入和输出做相应的升维和降维\n",
    "def comp_conv2d(conv2d, X):\n",
    "    # (1, 1)代表批量大小和通道数（“多输入通道和多输出通道”一节将介绍）均为1\n",
    "    X = X.view((1, 1) + X.shape)\n",
    "    Y = conv2d(X)\n",
    "    return Y.view(Y.shape[2:])  # 排除不关心的前两维：批量和通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "conv2d = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, padding=1)\n",
    "\n",
    "X = torch.rand(8, 8)\n",
    "comp_conv2d(conv2d, X).shape\n",
    "\n",
    "print(conv2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 步长"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 多输入和输出通道"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 多输入通道\n",
    "\n",
    "#### 多输入，但是单输出。在每个通道上，二维输入数组与二维核数组做互相关运算，再按通道相加即得到输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "import d2lzh_pytorch as d2l\n",
    "\n",
    "def conv2d_multi_in(X, K):\n",
    "    # 沿着x和k的第0维，分别计算再相加\n",
    "    res = corr2d(X[0, :, :], K[0, :, :])\n",
    "    for i in range(1, X.shape[0]):\n",
    "        res += corr2d(X[i, :, :], K[i, :, :])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1, 2],\n",
      "         [3, 4, 5],\n",
      "         [6, 7, 8]],\n",
      "\n",
      "        [[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]])\n",
      "tensor([[[0, 1],\n",
      "         [2, 3]],\n",
      "\n",
      "        [[1, 2],\n",
      "         [3, 4]]])\n",
      "torch.Size([2, 2, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  72.],\n",
       "        [104., 120.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[[0, 1, 2], [3, 4, 5], [6, 7, 8]],\n",
    "              [[1, 2, 3], [4, 5, 6], [7, 8, 9]]])\n",
    "K = torch.tensor([[[0, 1], [2, 3]], [[1, 2], [3, 4]]])\n",
    "\n",
    "print(X)\n",
    "print(K)\n",
    "print(K.shape)\n",
    "\n",
    "conv2d_multi_in(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 多输出通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out(X, K):\n",
    "    # 对K的第0维遍历，每次同输入X做互相关计算。所有结果使用stack函数合并在一起\n",
    "    return torch.stack([corr2d_multi_in(X, k) for k in K])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4  池化层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def pool2d(X, pool_size, mode='max'):\n",
    "    X = X.float()\n",
    "    p_h, p_w = pool_size\n",
    "    Y = torch.zeros(X.shape[0] - p_h + 1, X.shape[1] - p_w + 1)\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode == 'max':\n",
    "                Y[i,j] = X[i: i + p_h, j: j + p_w].max()\n",
    "            if mode == 'avg':\n",
    "                Y[i,j] = X[i: i + p_h, j: j + p_w].mean()\n",
    "    return Y\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n",
    "pool2d(X, (2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 LeNet卷积神经网络\n",
    "\n",
    "\n",
    "## 多层感知机问题:\n",
    "- 图像在同一列邻近的像素在这个向量中可能相距较远。它们构成的模式可能难以被模型识别\n",
    "- 对于大尺寸的输入图像，使用全连接层容易造成模型过大。假设输入是高和宽均为1000像素的彩色照片（含3个通道）。即使全连接层输出个数仍是256，该层权重参数的形状是3,000,000×256：它占用了大约3 GB的内存或显存。这带来过复杂的模型和过高的存储开销。\n",
    "\n",
    "## 卷积层\n",
    "- 卷积层保留输入形状，使图像的像素在高和宽两个方向上的相关性均可能被有效识别\n",
    "- 卷积层通过滑动窗口将同一卷积核与不同位置的输入重复计算，从而避免参数尺寸过大\n",
    "\n",
    "\n",
    "- 卷积层用来识别图像里的空间模式，如线条和物体局部\n",
    "- 最大池化层则用来降低卷积层对位置的敏感性，池化窗口与步幅形状相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time \n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "import d2lzh_pytorch as d2l\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "class Flatten(torch.nn.Module):  #展平操作\n",
    "    def forward(self, x):\n",
    "        return x.view(x.shape[0], -1)\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 5, padding=2),# 1@in_channels, 6@out_channels, 5*5@kernel_size\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(2, 2), # kernel_size, stride\n",
    "            \n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.Sigmoid(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "            \n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(          \n",
    "            Flatten(),\n",
    "            nn.Linear(16*5*5, 120),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(84, 10),\n",
    "        )\n",
    "    \n",
    "    def forward(self, img):\n",
    "        feature = self.conv(img)\n",
    "        output = self.fc(feature)\n",
    "        return output\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): Sigmoid()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): Sigmoid()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Flatten()\n",
      "    (1): Linear(in_features=400, out_features=120, bias=True)\n",
      "    (2): Sigmoid()\n",
      "    (3): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (4): Sigmoid()\n",
      "    (5): Linear(in_features=84, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = LeNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1 评估准确度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net, device=None):\n",
    "    if device is None and isinstance(net, torch.nn.Module):\n",
    "        # 如果没指定device就使用net的device\n",
    "        device = list(net.parameters())[0].device\n",
    "    acc_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(net, torch.nn.Module):\n",
    "                net.eval() # 评估模式, 这会关闭dropout\n",
    "                acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
    "                net.train() # 改回训练模式\n",
    "            else: # 自定义的模型, 3.13节之后不会用到, 不考虑GPU\n",
    "                if('is_training' in net.__code__.co_varnames): # 如果有is_training这个参数\n",
    "                    # 将is_training设置成False\n",
    "                    acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item() \n",
    "                else:\n",
    "                    acc_sum += (net(X).argmax(dim=1) == y).float().sum().item() \n",
    "            n += y.shape[0]\n",
    "    return acc_sum / n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2 训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_cnn(net, train_iter, test_iter, batch_size, optimizer, device,\n",
    "             num_epochs):\n",
    "    \n",
    "    net = net.to(device)\n",
    "    print('training on', device)\n",
    "    \n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, batch_count, start = 0.0, 0.0, 0, 0, time.time()\n",
    "        for X,y in train_iter:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_l_sum += l.cpu().item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\n",
    "            n += y.shape[0]\n",
    "            batch_count += 1\n",
    "            test_acc = evaluate_accuracy(test_iter, net)\n",
    "            print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 28, 28])\n",
      "torch.Size([256])\n",
      "tensor([[ 0.8553, -0.0314,  0.0197,  ...,  0.1979, -0.8129, -0.0661],\n",
      "        [ 0.8554, -0.0314,  0.0196,  ...,  0.1978, -0.8129, -0.0662],\n",
      "        [ 0.8553, -0.0313,  0.0197,  ...,  0.1979, -0.8129, -0.0661],\n",
      "        ...,\n",
      "        [ 0.8552, -0.0312,  0.0197,  ...,  0.1979, -0.8127, -0.0661],\n",
      "        [ 0.8554, -0.0313,  0.0196,  ...,  0.1979, -0.8128, -0.0662],\n",
      "        [ 0.8554, -0.0314,  0.0197,  ...,  0.1979, -0.8128, -0.0661]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "for X,y in train_iter:\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    y_hat = net(X)\n",
    "    print(y_hat)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cpu\n",
      "epoch 1, loss 2.3768, train acc 0.078, test acc 0.100, time 2.8 sec\n",
      "epoch 1, loss 2.3707, train acc 0.092, test acc 0.100, time 5.4 sec\n",
      "epoch 1, loss 2.3578, train acc 0.100, test acc 0.100, time 8.0 sec\n",
      "epoch 1, loss 2.3458, train acc 0.105, test acc 0.100, time 10.5 sec\n",
      "epoch 1, loss 2.3402, train acc 0.102, test acc 0.100, time 13.1 sec\n",
      "epoch 1, loss 2.3350, train acc 0.104, test acc 0.100, time 15.6 sec\n",
      "epoch 1, loss 2.3311, train acc 0.104, test acc 0.100, time 18.1 sec\n",
      "epoch 1, loss 2.3283, train acc 0.107, test acc 0.100, time 20.6 sec\n",
      "epoch 1, loss 2.3248, train acc 0.109, test acc 0.100, time 23.1 sec\n",
      "epoch 1, loss 2.3225, train acc 0.107, test acc 0.100, time 26.2 sec\n",
      "epoch 1, loss 2.3204, train acc 0.107, test acc 0.100, time 29.3 sec\n",
      "epoch 1, loss 2.3194, train acc 0.106, test acc 0.100, time 33.1 sec\n",
      "epoch 1, loss 2.3189, train acc 0.106, test acc 0.100, time 35.8 sec\n",
      "epoch 1, loss 2.3176, train acc 0.106, test acc 0.100, time 39.2 sec\n",
      "epoch 1, loss 2.3175, train acc 0.105, test acc 0.100, time 42.3 sec\n",
      "epoch 1, loss 2.3168, train acc 0.104, test acc 0.100, time 45.2 sec\n",
      "epoch 1, loss 2.3163, train acc 0.104, test acc 0.100, time 48.3 sec\n",
      "epoch 1, loss 2.3156, train acc 0.104, test acc 0.100, time 51.3 sec\n",
      "epoch 1, loss 2.3151, train acc 0.103, test acc 0.100, time 54.9 sec\n",
      "epoch 1, loss 2.3145, train acc 0.103, test acc 0.100, time 57.5 sec\n",
      "epoch 1, loss 2.3140, train acc 0.103, test acc 0.100, time 60.1 sec\n",
      "epoch 1, loss 2.3135, train acc 0.103, test acc 0.100, time 62.6 sec\n",
      "epoch 1, loss 2.3134, train acc 0.102, test acc 0.100, time 65.4 sec\n",
      "epoch 1, loss 2.3131, train acc 0.101, test acc 0.100, time 67.9 sec\n",
      "epoch 1, loss 2.3126, train acc 0.101, test acc 0.100, time 70.6 sec\n",
      "epoch 1, loss 2.3124, train acc 0.100, test acc 0.100, time 73.1 sec\n",
      "epoch 1, loss 2.3120, train acc 0.101, test acc 0.100, time 75.7 sec\n",
      "epoch 1, loss 2.3114, train acc 0.102, test acc 0.100, time 78.2 sec\n",
      "epoch 1, loss 2.3110, train acc 0.103, test acc 0.100, time 80.8 sec\n",
      "epoch 1, loss 2.3107, train acc 0.103, test acc 0.100, time 83.4 sec\n",
      "epoch 1, loss 2.3105, train acc 0.102, test acc 0.100, time 85.9 sec\n",
      "epoch 1, loss 2.3100, train acc 0.103, test acc 0.100, time 89.1 sec\n",
      "epoch 1, loss 2.3101, train acc 0.103, test acc 0.100, time 91.8 sec\n",
      "epoch 1, loss 2.3106, train acc 0.102, test acc 0.100, time 94.4 sec\n",
      "epoch 1, loss 2.3104, train acc 0.103, test acc 0.100, time 96.9 sec\n",
      "epoch 1, loss 2.3103, train acc 0.103, test acc 0.100, time 99.4 sec\n",
      "epoch 1, loss 2.3100, train acc 0.103, test acc 0.100, time 102.5 sec\n",
      "epoch 1, loss 2.3100, train acc 0.103, test acc 0.100, time 105.5 sec\n",
      "epoch 1, loss 2.3100, train acc 0.102, test acc 0.100, time 108.0 sec\n",
      "epoch 1, loss 2.3099, train acc 0.102, test acc 0.100, time 110.5 sec\n",
      "epoch 1, loss 2.3098, train acc 0.102, test acc 0.100, time 113.0 sec\n",
      "epoch 1, loss 2.3095, train acc 0.101, test acc 0.100, time 115.6 sec\n",
      "epoch 1, loss 2.3094, train acc 0.101, test acc 0.100, time 118.1 sec\n",
      "epoch 1, loss 2.3092, train acc 0.101, test acc 0.100, time 120.6 sec\n",
      "epoch 1, loss 2.3091, train acc 0.102, test acc 0.100, time 123.6 sec\n",
      "epoch 1, loss 2.3091, train acc 0.102, test acc 0.100, time 126.6 sec\n",
      "epoch 1, loss 2.3090, train acc 0.102, test acc 0.100, time 129.4 sec\n",
      "epoch 1, loss 2.3088, train acc 0.103, test acc 0.100, time 132.1 sec\n",
      "epoch 1, loss 2.3087, train acc 0.103, test acc 0.100, time 134.6 sec\n",
      "epoch 1, loss 2.3086, train acc 0.103, test acc 0.100, time 137.2 sec\n",
      "epoch 1, loss 2.3085, train acc 0.103, test acc 0.100, time 140.9 sec\n",
      "epoch 1, loss 2.3084, train acc 0.103, test acc 0.100, time 144.7 sec\n",
      "epoch 1, loss 2.3082, train acc 0.104, test acc 0.100, time 147.6 sec\n",
      "epoch 1, loss 2.3081, train acc 0.104, test acc 0.101, time 150.2 sec\n",
      "epoch 1, loss 2.3080, train acc 0.104, test acc 0.100, time 152.7 sec\n",
      "epoch 1, loss 2.3080, train acc 0.104, test acc 0.100, time 155.2 sec\n",
      "epoch 1, loss 2.3079, train acc 0.104, test acc 0.100, time 157.8 sec\n",
      "epoch 1, loss 2.3077, train acc 0.104, test acc 0.100, time 160.4 sec\n",
      "epoch 1, loss 2.3077, train acc 0.104, test acc 0.100, time 163.0 sec\n",
      "epoch 1, loss 2.3077, train acc 0.104, test acc 0.100, time 165.5 sec\n",
      "epoch 1, loss 2.3076, train acc 0.103, test acc 0.100, time 168.1 sec\n",
      "epoch 1, loss 2.3075, train acc 0.103, test acc 0.100, time 170.6 sec\n",
      "epoch 1, loss 2.3076, train acc 0.102, test acc 0.100, time 173.4 sec\n",
      "epoch 1, loss 2.3077, train acc 0.102, test acc 0.100, time 176.2 sec\n",
      "epoch 1, loss 2.3076, train acc 0.102, test acc 0.100, time 178.8 sec\n",
      "epoch 1, loss 2.3077, train acc 0.102, test acc 0.100, time 181.3 sec\n",
      "epoch 1, loss 2.3077, train acc 0.103, test acc 0.127, time 184.1 sec\n",
      "epoch 1, loss 2.3075, train acc 0.103, test acc 0.100, time 186.6 sec\n",
      "epoch 1, loss 2.3075, train acc 0.103, test acc 0.100, time 189.1 sec\n",
      "epoch 1, loss 2.3074, train acc 0.104, test acc 0.100, time 191.6 sec\n",
      "epoch 1, loss 2.3074, train acc 0.103, test acc 0.100, time 194.2 sec\n",
      "epoch 1, loss 2.3075, train acc 0.103, test acc 0.100, time 196.9 sec\n",
      "epoch 1, loss 2.3076, train acc 0.103, test acc 0.100, time 200.5 sec\n",
      "epoch 1, loss 2.3077, train acc 0.103, test acc 0.100, time 204.3 sec\n",
      "epoch 1, loss 2.3076, train acc 0.103, test acc 0.100, time 209.7 sec\n",
      "epoch 1, loss 2.3077, train acc 0.102, test acc 0.100, time 213.3 sec\n",
      "epoch 1, loss 2.3079, train acc 0.102, test acc 0.100, time 218.3 sec\n",
      "epoch 1, loss 2.3077, train acc 0.102, test acc 0.100, time 222.5 sec\n",
      "epoch 1, loss 2.3077, train acc 0.102, test acc 0.100, time 225.3 sec\n",
      "epoch 1, loss 2.3077, train acc 0.102, test acc 0.100, time 229.2 sec\n",
      "epoch 1, loss 2.3076, train acc 0.103, test acc 0.100, time 234.3 sec\n",
      "epoch 1, loss 2.3076, train acc 0.102, test acc 0.100, time 238.5 sec\n",
      "epoch 1, loss 2.3075, train acc 0.103, test acc 0.100, time 241.3 sec\n",
      "epoch 1, loss 2.3075, train acc 0.103, test acc 0.100, time 244.4 sec\n",
      "epoch 1, loss 2.3074, train acc 0.103, test acc 0.100, time 247.5 sec\n",
      "epoch 1, loss 2.3073, train acc 0.103, test acc 0.100, time 250.3 sec\n",
      "epoch 1, loss 2.3073, train acc 0.103, test acc 0.100, time 253.2 sec\n",
      "epoch 1, loss 2.3072, train acc 0.103, test acc 0.100, time 256.4 sec\n",
      "epoch 1, loss 2.3071, train acc 0.102, test acc 0.100, time 259.4 sec\n",
      "epoch 1, loss 2.3071, train acc 0.102, test acc 0.100, time 262.1 sec\n",
      "epoch 1, loss 2.3071, train acc 0.102, test acc 0.100, time 265.2 sec\n",
      "epoch 1, loss 2.3070, train acc 0.102, test acc 0.100, time 268.8 sec\n",
      "epoch 1, loss 2.3070, train acc 0.101, test acc 0.100, time 271.5 sec\n",
      "epoch 1, loss 2.3071, train acc 0.102, test acc 0.100, time 274.4 sec\n",
      "epoch 1, loss 2.3071, train acc 0.101, test acc 0.181, time 277.5 sec\n",
      "epoch 1, loss 2.3071, train acc 0.102, test acc 0.100, time 280.4 sec\n",
      "epoch 1, loss 2.3070, train acc 0.101, test acc 0.100, time 283.2 sec\n",
      "epoch 1, loss 2.3070, train acc 0.101, test acc 0.177, time 286.7 sec\n",
      "epoch 1, loss 2.3069, train acc 0.102, test acc 0.100, time 289.3 sec\n",
      "epoch 1, loss 2.3067, train acc 0.102, test acc 0.100, time 292.0 sec\n",
      "epoch 1, loss 2.3066, train acc 0.102, test acc 0.100, time 295.3 sec\n",
      "epoch 1, loss 2.3066, train acc 0.102, test acc 0.100, time 298.1 sec\n",
      "epoch 1, loss 2.3065, train acc 0.102, test acc 0.100, time 301.2 sec\n",
      "epoch 1, loss 2.3064, train acc 0.102, test acc 0.100, time 304.4 sec\n",
      "epoch 1, loss 2.3063, train acc 0.102, test acc 0.149, time 307.5 sec\n",
      "epoch 1, loss 2.3063, train acc 0.102, test acc 0.172, time 310.1 sec\n",
      "epoch 1, loss 2.3061, train acc 0.103, test acc 0.127, time 313.2 sec\n",
      "epoch 1, loss 2.3059, train acc 0.103, test acc 0.141, time 316.4 sec\n",
      "epoch 1, loss 2.3057, train acc 0.103, test acc 0.145, time 319.3 sec\n",
      "epoch 1, loss 2.3054, train acc 0.103, test acc 0.138, time 321.8 sec\n",
      "epoch 1, loss 2.3052, train acc 0.103, test acc 0.143, time 324.5 sec\n",
      "epoch 1, loss 2.3049, train acc 0.103, test acc 0.159, time 327.6 sec\n",
      "epoch 1, loss 2.3046, train acc 0.104, test acc 0.184, time 330.8 sec\n",
      "epoch 1, loss 2.3042, train acc 0.105, test acc 0.166, time 334.0 sec\n",
      "epoch 1, loss 2.3039, train acc 0.106, test acc 0.175, time 336.8 sec\n",
      "epoch 1, loss 2.3034, train acc 0.106, test acc 0.181, time 340.1 sec\n",
      "epoch 1, loss 2.3029, train acc 0.107, test acc 0.183, time 343.2 sec\n",
      "epoch 1, loss 2.3023, train acc 0.108, test acc 0.183, time 347.0 sec\n",
      "epoch 1, loss 2.3017, train acc 0.108, test acc 0.183, time 350.1 sec\n",
      "epoch 1, loss 2.3010, train acc 0.109, test acc 0.182, time 353.1 sec\n",
      "epoch 1, loss 2.3002, train acc 0.110, test acc 0.205, time 355.9 sec\n",
      "epoch 1, loss 2.2995, train acc 0.111, test acc 0.261, time 358.4 sec\n",
      "epoch 1, loss 2.2985, train acc 0.112, test acc 0.290, time 362.2 sec\n",
      "epoch 1, loss 2.2976, train acc 0.113, test acc 0.307, time 364.9 sec\n",
      "epoch 1, loss 2.2966, train acc 0.115, test acc 0.319, time 367.9 sec\n",
      "epoch 1, loss 2.2953, train acc 0.116, test acc 0.322, time 370.8 sec\n",
      "epoch 1, loss 2.2940, train acc 0.118, test acc 0.340, time 373.4 sec\n",
      "epoch 1, loss 2.2927, train acc 0.120, test acc 0.392, time 376.2 sec\n",
      "epoch 1, loss 2.2911, train acc 0.122, test acc 0.424, time 379.0 sec\n",
      "epoch 1, loss 2.2893, train acc 0.125, test acc 0.374, time 382.3 sec\n",
      "epoch 1, loss 2.2876, train acc 0.127, test acc 0.345, time 385.0 sec\n",
      "epoch 1, loss 2.2858, train acc 0.129, test acc 0.314, time 388.3 sec\n",
      "epoch 1, loss 2.2839, train acc 0.130, test acc 0.270, time 393.0 sec\n",
      "epoch 1, loss 2.2820, train acc 0.132, test acc 0.278, time 396.3 sec\n",
      "epoch 1, loss 2.2801, train acc 0.132, test acc 0.312, time 400.0 sec\n",
      "epoch 1, loss 2.2781, train acc 0.133, test acc 0.331, time 402.9 sec\n",
      "epoch 1, loss 2.2760, train acc 0.135, test acc 0.343, time 405.9 sec\n",
      "epoch 1, loss 2.2739, train acc 0.136, test acc 0.336, time 409.2 sec\n",
      "epoch 1, loss 2.2714, train acc 0.138, test acc 0.336, time 412.6 sec\n",
      "epoch 1, loss 2.2689, train acc 0.139, test acc 0.332, time 415.7 sec\n",
      "epoch 1, loss 2.2661, train acc 0.140, test acc 0.325, time 418.9 sec\n",
      "epoch 1, loss 2.2636, train acc 0.142, test acc 0.317, time 422.5 sec\n",
      "epoch 1, loss 2.2607, train acc 0.143, test acc 0.317, time 425.2 sec\n",
      "epoch 1, loss 2.2579, train acc 0.144, test acc 0.320, time 428.2 sec\n",
      "epoch 1, loss 2.2552, train acc 0.146, test acc 0.328, time 431.1 sec\n",
      "epoch 1, loss 2.2522, train acc 0.147, test acc 0.337, time 433.9 sec\n",
      "epoch 1, loss 2.2493, train acc 0.148, test acc 0.349, time 436.7 sec\n",
      "epoch 1, loss 2.2460, train acc 0.150, test acc 0.358, time 439.5 sec\n",
      "epoch 1, loss 2.2427, train acc 0.151, test acc 0.362, time 442.3 sec\n",
      "epoch 1, loss 2.2395, train acc 0.152, test acc 0.370, time 445.5 sec\n",
      "epoch 1, loss 2.2361, train acc 0.154, test acc 0.382, time 448.9 sec\n",
      "epoch 1, loss 2.2329, train acc 0.155, test acc 0.409, time 452.2 sec\n",
      "epoch 1, loss 2.2296, train acc 0.156, test acc 0.404, time 455.0 sec\n",
      "epoch 1, loss 2.2259, train acc 0.157, test acc 0.418, time 457.9 sec\n",
      "epoch 1, loss 2.2226, train acc 0.159, test acc 0.433, time 460.9 sec\n",
      "epoch 1, loss 2.2189, train acc 0.161, test acc 0.449, time 463.5 sec\n",
      "epoch 1, loss 2.2155, train acc 0.163, test acc 0.461, time 466.2 sec\n",
      "epoch 1, loss 2.2115, train acc 0.165, test acc 0.472, time 469.0 sec\n",
      "epoch 1, loss 2.2077, train acc 0.167, test acc 0.481, time 472.0 sec\n",
      "epoch 1, loss 2.2040, train acc 0.169, test acc 0.489, time 475.0 sec\n",
      "epoch 1, loss 2.1999, train acc 0.171, test acc 0.500, time 477.7 sec\n",
      "epoch 1, loss 2.1960, train acc 0.173, test acc 0.509, time 481.3 sec\n",
      "epoch 1, loss 2.1924, train acc 0.175, test acc 0.512, time 484.5 sec\n",
      "epoch 1, loss 2.1884, train acc 0.177, test acc 0.516, time 487.6 sec\n",
      "epoch 1, loss 2.1847, train acc 0.179, test acc 0.518, time 490.6 sec\n",
      "epoch 1, loss 2.1807, train acc 0.181, test acc 0.516, time 493.4 sec\n",
      "epoch 1, loss 2.1767, train acc 0.183, test acc 0.515, time 496.6 sec\n",
      "epoch 1, loss 2.1728, train acc 0.185, test acc 0.515, time 500.0 sec\n",
      "epoch 1, loss 2.1686, train acc 0.187, test acc 0.512, time 502.7 sec\n",
      "epoch 1, loss 2.1643, train acc 0.189, test acc 0.508, time 505.4 sec\n",
      "epoch 1, loss 2.1602, train acc 0.191, test acc 0.506, time 508.2 sec\n",
      "epoch 1, loss 2.1559, train acc 0.193, test acc 0.508, time 511.6 sec\n",
      "epoch 1, loss 2.1520, train acc 0.195, test acc 0.509, time 515.0 sec\n",
      "epoch 1, loss 2.1480, train acc 0.197, test acc 0.508, time 518.0 sec\n",
      "epoch 1, loss 2.1435, train acc 0.199, test acc 0.507, time 521.2 sec\n",
      "epoch 1, loss 2.1396, train acc 0.200, test acc 0.511, time 524.6 sec\n",
      "epoch 1, loss 2.1352, train acc 0.202, test acc 0.513, time 527.4 sec\n",
      "epoch 1, loss 2.1308, train acc 0.204, test acc 0.514, time 530.4 sec\n",
      "epoch 1, loss 2.1265, train acc 0.205, test acc 0.514, time 533.9 sec\n",
      "epoch 1, loss 2.1226, train acc 0.207, test acc 0.513, time 536.8 sec\n",
      "epoch 1, loss 2.1184, train acc 0.209, test acc 0.513, time 539.5 sec\n",
      "epoch 1, loss 2.1141, train acc 0.211, test acc 0.512, time 542.3 sec\n",
      "epoch 1, loss 2.1100, train acc 0.213, test acc 0.513, time 545.3 sec\n",
      "epoch 1, loss 2.1057, train acc 0.214, test acc 0.522, time 548.5 sec\n",
      "epoch 1, loss 2.1015, train acc 0.216, test acc 0.521, time 551.5 sec\n",
      "epoch 1, loss 2.0974, train acc 0.217, test acc 0.529, time 555.1 sec\n",
      "epoch 1, loss 2.0929, train acc 0.219, test acc 0.537, time 558.3 sec\n",
      "epoch 1, loss 2.0887, train acc 0.221, test acc 0.544, time 561.0 sec\n",
      "epoch 1, loss 2.0845, train acc 0.222, test acc 0.544, time 563.9 sec\n",
      "epoch 1, loss 2.0805, train acc 0.224, test acc 0.547, time 566.6 sec\n",
      "epoch 1, loss 2.0767, train acc 0.225, test acc 0.552, time 569.5 sec\n",
      "epoch 1, loss 2.0727, train acc 0.227, test acc 0.548, time 572.5 sec\n",
      "epoch 1, loss 2.0687, train acc 0.229, test acc 0.545, time 575.9 sec\n",
      "epoch 1, loss 2.0646, train acc 0.230, test acc 0.542, time 579.1 sec\n",
      "epoch 1, loss 2.0608, train acc 0.232, test acc 0.540, time 581.8 sec\n",
      "epoch 1, loss 2.0568, train acc 0.234, test acc 0.539, time 584.6 sec\n",
      "epoch 1, loss 2.0530, train acc 0.235, test acc 0.539, time 587.5 sec\n",
      "epoch 1, loss 2.0489, train acc 0.237, test acc 0.542, time 590.6 sec\n",
      "epoch 1, loss 2.0450, train acc 0.238, test acc 0.546, time 593.2 sec\n",
      "epoch 1, loss 2.0410, train acc 0.240, test acc 0.550, time 595.9 sec\n",
      "epoch 1, loss 2.0368, train acc 0.242, test acc 0.550, time 599.0 sec\n",
      "epoch 1, loss 2.0331, train acc 0.243, test acc 0.552, time 602.1 sec\n",
      "epoch 1, loss 2.0292, train acc 0.244, test acc 0.556, time 604.8 sec\n",
      "epoch 1, loss 2.0249, train acc 0.246, test acc 0.558, time 608.0 sec\n",
      "epoch 1, loss 2.0213, train acc 0.247, test acc 0.556, time 611.0 sec\n",
      "epoch 1, loss 2.0170, train acc 0.249, test acc 0.553, time 614.0 sec\n",
      "epoch 1, loss 2.0133, train acc 0.250, test acc 0.547, time 617.0 sec\n",
      "epoch 1, loss 2.0092, train acc 0.252, test acc 0.548, time 620.0 sec\n",
      "epoch 1, loss 2.0051, train acc 0.253, test acc 0.551, time 622.9 sec\n",
      "epoch 1, loss 2.0011, train acc 0.254, test acc 0.555, time 625.9 sec\n",
      "epoch 1, loss 1.9973, train acc 0.256, test acc 0.557, time 629.5 sec\n",
      "epoch 1, loss 1.9938, train acc 0.257, test acc 0.560, time 632.6 sec\n",
      "epoch 1, loss 1.9897, train acc 0.259, test acc 0.563, time 635.5 sec\n",
      "epoch 1, loss 1.9858, train acc 0.260, test acc 0.567, time 639.1 sec\n",
      "epoch 1, loss 1.9822, train acc 0.262, test acc 0.571, time 645.4 sec\n",
      "epoch 1, loss 1.9785, train acc 0.263, test acc 0.573, time 648.9 sec\n",
      "epoch 1, loss 1.9748, train acc 0.264, test acc 0.576, time 651.7 sec\n",
      "epoch 1, loss 1.9712, train acc 0.266, test acc 0.577, time 655.1 sec\n",
      "epoch 1, loss 1.9674, train acc 0.267, test acc 0.576, time 657.7 sec\n",
      "epoch 1, loss 1.9635, train acc 0.269, test acc 0.569, time 660.2 sec\n",
      "epoch 1, loss 1.9597, train acc 0.270, test acc 0.556, time 663.1 sec\n",
      "epoch 1, loss 1.9561, train acc 0.271, test acc 0.547, time 665.9 sec\n",
      "epoch 1, loss 1.9525, train acc 0.273, test acc 0.551, time 668.6 sec\n",
      "epoch 1, loss 1.9487, train acc 0.274, test acc 0.565, time 671.4 sec\n",
      "epoch 1, loss 1.9452, train acc 0.275, test acc 0.577, time 673.9 sec\n",
      "epoch 1, loss 1.9416, train acc 0.276, test acc 0.583, time 676.4 sec\n",
      "epoch 1, loss 1.9380, train acc 0.278, test acc 0.584, time 678.9 sec\n",
      "epoch 1, loss 1.9346, train acc 0.279, test acc 0.581, time 681.4 sec\n",
      "epoch 1, loss 1.9311, train acc 0.280, test acc 0.582, time 683.9 sec\n",
      "epoch 1, loss 1.9274, train acc 0.282, test acc 0.582, time 686.4 sec\n",
      "epoch 1, loss 1.9241, train acc 0.283, test acc 0.579, time 688.9 sec\n",
      "epoch 1, loss 1.9203, train acc 0.284, test acc 0.571, time 691.4 sec\n",
      "epoch 1, loss 1.9169, train acc 0.285, test acc 0.565, time 693.9 sec\n",
      "epoch 1, loss 1.9134, train acc 0.287, test acc 0.566, time 696.5 sec\n",
      "epoch 1, loss 1.9097, train acc 0.287, test acc 0.566, time 698.9 sec\n",
      "epoch 2, loss 1.0492, train acc 0.594, test acc 0.567, time 2.5 sec\n",
      "epoch 2, loss 1.0897, train acc 0.578, test acc 0.568, time 5.0 sec\n",
      "epoch 2, loss 1.0897, train acc 0.585, test acc 0.571, time 7.5 sec\n",
      "epoch 2, loss 1.0957, train acc 0.574, test acc 0.572, time 10.0 sec\n",
      "epoch 2, loss 1.0886, train acc 0.587, test acc 0.572, time 12.5 sec\n",
      "epoch 2, loss 1.0894, train acc 0.581, test acc 0.571, time 15.0 sec\n",
      "epoch 2, loss 1.0872, train acc 0.579, test acc 0.570, time 17.5 sec\n",
      "epoch 2, loss 1.0896, train acc 0.578, test acc 0.569, time 20.0 sec\n",
      "epoch 2, loss 1.0827, train acc 0.577, test acc 0.566, time 22.5 sec\n",
      "epoch 2, loss 1.0771, train acc 0.574, test acc 0.566, time 25.0 sec\n",
      "epoch 2, loss 1.0703, train acc 0.579, test acc 0.561, time 27.5 sec\n",
      "epoch 2, loss 1.0658, train acc 0.579, test acc 0.560, time 30.0 sec\n",
      "epoch 2, loss 1.0715, train acc 0.576, test acc 0.558, time 32.5 sec\n",
      "epoch 2, loss 1.0697, train acc 0.575, test acc 0.555, time 35.0 sec\n",
      "epoch 2, loss 1.0677, train acc 0.572, test acc 0.557, time 37.5 sec\n",
      "epoch 2, loss 1.0644, train acc 0.574, test acc 0.560, time 40.0 sec\n",
      "epoch 2, loss 1.0604, train acc 0.576, test acc 0.569, time 42.5 sec\n",
      "epoch 2, loss 1.0638, train acc 0.574, test acc 0.581, time 45.0 sec\n",
      "epoch 2, loss 1.0612, train acc 0.575, test acc 0.589, time 47.5 sec\n",
      "epoch 2, loss 1.0622, train acc 0.574, test acc 0.591, time 50.0 sec\n",
      "epoch 2, loss 1.0595, train acc 0.577, test acc 0.594, time 52.6 sec\n",
      "epoch 2, loss 1.0603, train acc 0.578, test acc 0.596, time 55.2 sec\n",
      "epoch 2, loss 1.0592, train acc 0.578, test acc 0.594, time 57.7 sec\n",
      "epoch 2, loss 1.0582, train acc 0.577, test acc 0.593, time 60.3 sec\n",
      "epoch 2, loss 1.0578, train acc 0.577, test acc 0.592, time 62.9 sec\n",
      "epoch 2, loss 1.0560, train acc 0.578, test acc 0.593, time 65.4 sec\n",
      "epoch 2, loss 1.0552, train acc 0.578, test acc 0.594, time 67.9 sec\n",
      "epoch 2, loss 1.0553, train acc 0.578, test acc 0.595, time 70.5 sec\n",
      "epoch 2, loss 1.0546, train acc 0.579, test acc 0.595, time 73.0 sec\n",
      "epoch 2, loss 1.0536, train acc 0.580, test acc 0.596, time 75.5 sec\n",
      "epoch 2, loss 1.0535, train acc 0.580, test acc 0.599, time 78.0 sec\n",
      "epoch 2, loss 1.0558, train acc 0.580, test acc 0.601, time 80.6 sec\n",
      "epoch 2, loss 1.0545, train acc 0.580, test acc 0.602, time 83.0 sec\n",
      "epoch 2, loss 1.0551, train acc 0.580, test acc 0.602, time 85.5 sec\n",
      "epoch 2, loss 1.0541, train acc 0.582, test acc 0.602, time 88.0 sec\n",
      "epoch 2, loss 1.0531, train acc 0.581, test acc 0.600, time 90.6 sec\n",
      "epoch 2, loss 1.0533, train acc 0.581, test acc 0.595, time 93.1 sec\n",
      "epoch 2, loss 1.0530, train acc 0.582, test acc 0.593, time 95.6 sec\n",
      "epoch 2, loss 1.0519, train acc 0.583, test acc 0.593, time 98.1 sec\n",
      "epoch 2, loss 1.0524, train acc 0.582, test acc 0.593, time 100.6 sec\n",
      "epoch 2, loss 1.0516, train acc 0.582, test acc 0.592, time 103.1 sec\n",
      "epoch 2, loss 1.0522, train acc 0.582, test acc 0.590, time 105.6 sec\n",
      "epoch 2, loss 1.0499, train acc 0.583, test acc 0.590, time 108.1 sec\n",
      "epoch 2, loss 1.0501, train acc 0.583, test acc 0.589, time 110.6 sec\n",
      "epoch 2, loss 1.0483, train acc 0.584, test acc 0.587, time 113.1 sec\n",
      "epoch 2, loss 1.0497, train acc 0.583, test acc 0.587, time 115.6 sec\n",
      "epoch 2, loss 1.0491, train acc 0.582, test acc 0.588, time 118.2 sec\n",
      "epoch 2, loss 1.0476, train acc 0.583, test acc 0.586, time 120.7 sec\n",
      "epoch 2, loss 1.0458, train acc 0.583, test acc 0.592, time 123.2 sec\n",
      "epoch 2, loss 1.0428, train acc 0.584, test acc 0.597, time 125.7 sec\n",
      "epoch 2, loss 1.0432, train acc 0.585, test acc 0.598, time 128.2 sec\n",
      "epoch 2, loss 1.0430, train acc 0.584, test acc 0.598, time 130.8 sec\n",
      "epoch 2, loss 1.0424, train acc 0.584, test acc 0.598, time 133.3 sec\n",
      "epoch 2, loss 1.0414, train acc 0.584, test acc 0.599, time 135.8 sec\n",
      "epoch 2, loss 1.0409, train acc 0.584, test acc 0.599, time 138.3 sec\n",
      "epoch 2, loss 1.0399, train acc 0.585, test acc 0.599, time 140.8 sec\n",
      "epoch 2, loss 1.0386, train acc 0.584, test acc 0.604, time 143.3 sec\n",
      "epoch 2, loss 1.0396, train acc 0.584, test acc 0.604, time 145.8 sec\n",
      "epoch 2, loss 1.0383, train acc 0.584, test acc 0.608, time 148.3 sec\n",
      "epoch 2, loss 1.0380, train acc 0.585, test acc 0.616, time 150.8 sec\n",
      "epoch 2, loss 1.0373, train acc 0.585, test acc 0.614, time 153.3 sec\n",
      "epoch 2, loss 1.0369, train acc 0.585, test acc 0.613, time 155.8 sec\n",
      "epoch 2, loss 1.0360, train acc 0.585, test acc 0.612, time 158.4 sec\n",
      "epoch 2, loss 1.0355, train acc 0.585, test acc 0.615, time 160.8 sec\n",
      "epoch 2, loss 1.0335, train acc 0.586, test acc 0.615, time 163.3 sec\n",
      "epoch 2, loss 1.0323, train acc 0.585, test acc 0.615, time 165.9 sec\n",
      "epoch 2, loss 1.0312, train acc 0.585, test acc 0.613, time 168.4 sec\n",
      "epoch 2, loss 1.0301, train acc 0.585, test acc 0.613, time 170.9 sec\n",
      "epoch 2, loss 1.0292, train acc 0.585, test acc 0.615, time 173.4 sec\n",
      "epoch 2, loss 1.0290, train acc 0.585, test acc 0.618, time 175.9 sec\n",
      "epoch 2, loss 1.0271, train acc 0.587, test acc 0.622, time 178.4 sec\n",
      "epoch 2, loss 1.0262, train acc 0.587, test acc 0.622, time 181.0 sec\n",
      "epoch 2, loss 1.0259, train acc 0.588, test acc 0.623, time 183.5 sec\n",
      "epoch 2, loss 1.0253, train acc 0.588, test acc 0.623, time 186.0 sec\n",
      "epoch 2, loss 1.0236, train acc 0.589, test acc 0.620, time 188.6 sec\n",
      "epoch 2, loss 1.0233, train acc 0.589, test acc 0.617, time 191.2 sec\n",
      "epoch 2, loss 1.0222, train acc 0.590, test acc 0.615, time 193.7 sec\n",
      "epoch 2, loss 1.0210, train acc 0.591, test acc 0.609, time 196.2 sec\n",
      "epoch 2, loss 1.0200, train acc 0.591, test acc 0.608, time 198.7 sec\n",
      "epoch 2, loss 1.0188, train acc 0.591, test acc 0.606, time 201.2 sec\n",
      "epoch 2, loss 1.0183, train acc 0.591, test acc 0.605, time 203.7 sec\n",
      "epoch 2, loss 1.0174, train acc 0.592, test acc 0.608, time 206.2 sec\n",
      "epoch 2, loss 1.0156, train acc 0.593, test acc 0.613, time 208.7 sec\n",
      "epoch 2, loss 1.0146, train acc 0.593, test acc 0.614, time 211.3 sec\n",
      "epoch 2, loss 1.0136, train acc 0.594, test acc 0.615, time 213.8 sec\n",
      "epoch 2, loss 1.0125, train acc 0.594, test acc 0.612, time 216.3 sec\n",
      "epoch 2, loss 1.0128, train acc 0.593, test acc 0.610, time 218.8 sec\n",
      "epoch 2, loss 1.0115, train acc 0.594, test acc 0.609, time 221.3 sec\n",
      "epoch 2, loss 1.0125, train acc 0.593, test acc 0.614, time 223.8 sec\n",
      "epoch 2, loss 1.0115, train acc 0.593, test acc 0.615, time 226.3 sec\n",
      "epoch 2, loss 1.0112, train acc 0.593, test acc 0.615, time 228.8 sec\n",
      "epoch 2, loss 1.0102, train acc 0.593, test acc 0.616, time 231.3 sec\n",
      "epoch 2, loss 1.0091, train acc 0.593, test acc 0.617, time 233.8 sec\n",
      "epoch 2, loss 1.0081, train acc 0.594, test acc 0.618, time 236.4 sec\n",
      "epoch 2, loss 1.0081, train acc 0.593, test acc 0.619, time 238.9 sec\n",
      "epoch 2, loss 1.0076, train acc 0.593, test acc 0.620, time 241.4 sec\n",
      "epoch 2, loss 1.0071, train acc 0.594, test acc 0.621, time 243.9 sec\n",
      "epoch 2, loss 1.0070, train acc 0.594, test acc 0.624, time 246.4 sec\n",
      "epoch 2, loss 1.0058, train acc 0.594, test acc 0.627, time 249.0 sec\n",
      "epoch 2, loss 1.0048, train acc 0.594, test acc 0.630, time 251.5 sec\n",
      "epoch 2, loss 1.0046, train acc 0.594, test acc 0.633, time 254.0 sec\n",
      "epoch 2, loss 1.0042, train acc 0.594, test acc 0.633, time 256.5 sec\n",
      "epoch 2, loss 1.0037, train acc 0.595, test acc 0.633, time 259.0 sec\n",
      "epoch 2, loss 1.0027, train acc 0.595, test acc 0.633, time 261.5 sec\n",
      "epoch 2, loss 1.0021, train acc 0.595, test acc 0.631, time 264.0 sec\n",
      "epoch 2, loss 1.0005, train acc 0.596, test acc 0.628, time 266.5 sec\n",
      "epoch 2, loss 0.9994, train acc 0.597, test acc 0.628, time 269.0 sec\n",
      "epoch 2, loss 0.9986, train acc 0.597, test acc 0.627, time 271.5 sec\n",
      "epoch 2, loss 0.9987, train acc 0.598, test acc 0.626, time 274.1 sec\n",
      "epoch 2, loss 0.9983, train acc 0.598, test acc 0.625, time 277.1 sec\n",
      "epoch 2, loss 0.9970, train acc 0.598, test acc 0.625, time 279.6 sec\n",
      "epoch 2, loss 0.9969, train acc 0.598, test acc 0.624, time 282.1 sec\n",
      "epoch 2, loss 0.9961, train acc 0.599, test acc 0.623, time 284.6 sec\n",
      "epoch 2, loss 0.9951, train acc 0.599, test acc 0.625, time 287.1 sec\n",
      "epoch 2, loss 0.9946, train acc 0.599, test acc 0.625, time 289.7 sec\n",
      "epoch 2, loss 0.9936, train acc 0.600, test acc 0.629, time 292.2 sec\n",
      "epoch 2, loss 0.9926, train acc 0.600, test acc 0.632, time 294.7 sec\n",
      "epoch 2, loss 0.9916, train acc 0.600, test acc 0.633, time 297.1 sec\n",
      "epoch 2, loss 0.9903, train acc 0.601, test acc 0.634, time 299.7 sec\n",
      "epoch 2, loss 0.9890, train acc 0.602, test acc 0.632, time 302.2 sec\n",
      "epoch 2, loss 0.9882, train acc 0.603, test acc 0.632, time 304.8 sec\n",
      "epoch 2, loss 0.9875, train acc 0.603, test acc 0.631, time 307.3 sec\n",
      "epoch 2, loss 0.9868, train acc 0.603, test acc 0.630, time 309.9 sec\n",
      "epoch 2, loss 0.9866, train acc 0.603, test acc 0.628, time 312.4 sec\n",
      "epoch 2, loss 0.9861, train acc 0.603, test acc 0.628, time 314.9 sec\n",
      "epoch 2, loss 0.9848, train acc 0.604, test acc 0.630, time 317.5 sec\n",
      "epoch 2, loss 0.9839, train acc 0.604, test acc 0.632, time 319.9 sec\n",
      "epoch 2, loss 0.9830, train acc 0.605, test acc 0.632, time 322.4 sec\n",
      "epoch 2, loss 0.9828, train acc 0.605, test acc 0.633, time 324.9 sec\n",
      "epoch 2, loss 0.9825, train acc 0.605, test acc 0.635, time 327.4 sec\n",
      "epoch 2, loss 0.9817, train acc 0.605, test acc 0.636, time 330.0 sec\n",
      "epoch 2, loss 0.9812, train acc 0.605, test acc 0.638, time 332.5 sec\n",
      "epoch 2, loss 0.9805, train acc 0.605, test acc 0.641, time 335.0 sec\n",
      "epoch 2, loss 0.9798, train acc 0.606, test acc 0.643, time 337.4 sec\n",
      "epoch 2, loss 0.9788, train acc 0.606, test acc 0.647, time 340.0 sec\n",
      "epoch 2, loss 0.9784, train acc 0.607, test acc 0.645, time 342.5 sec\n",
      "epoch 2, loss 0.9778, train acc 0.607, test acc 0.647, time 345.0 sec\n",
      "epoch 2, loss 0.9774, train acc 0.607, test acc 0.644, time 347.5 sec\n",
      "epoch 2, loss 0.9770, train acc 0.607, test acc 0.644, time 350.0 sec\n",
      "epoch 2, loss 0.9769, train acc 0.607, test acc 0.644, time 352.5 sec\n",
      "epoch 2, loss 0.9758, train acc 0.608, test acc 0.644, time 355.0 sec\n",
      "epoch 2, loss 0.9753, train acc 0.608, test acc 0.646, time 357.5 sec\n",
      "epoch 2, loss 0.9747, train acc 0.608, test acc 0.648, time 360.0 sec\n",
      "epoch 2, loss 0.9738, train acc 0.608, test acc 0.652, time 362.5 sec\n",
      "epoch 2, loss 0.9737, train acc 0.608, test acc 0.656, time 365.1 sec\n",
      "epoch 2, loss 0.9726, train acc 0.609, test acc 0.660, time 367.7 sec\n",
      "epoch 2, loss 0.9722, train acc 0.609, test acc 0.656, time 370.3 sec\n",
      "epoch 2, loss 0.9718, train acc 0.609, test acc 0.656, time 372.9 sec\n",
      "epoch 2, loss 0.9712, train acc 0.610, test acc 0.652, time 375.7 sec\n",
      "epoch 2, loss 0.9701, train acc 0.610, test acc 0.653, time 378.3 sec\n",
      "epoch 2, loss 0.9693, train acc 0.611, test acc 0.651, time 381.0 sec\n",
      "epoch 2, loss 0.9687, train acc 0.611, test acc 0.651, time 383.5 sec\n",
      "epoch 2, loss 0.9679, train acc 0.612, test acc 0.652, time 386.1 sec\n",
      "epoch 2, loss 0.9677, train acc 0.611, test acc 0.651, time 388.5 sec\n",
      "epoch 2, loss 0.9672, train acc 0.612, test acc 0.653, time 391.1 sec\n",
      "epoch 2, loss 0.9663, train acc 0.612, test acc 0.653, time 393.6 sec\n",
      "epoch 2, loss 0.9654, train acc 0.613, test acc 0.653, time 396.1 sec\n",
      "epoch 2, loss 0.9650, train acc 0.613, test acc 0.655, time 398.6 sec\n",
      "epoch 2, loss 0.9643, train acc 0.613, test acc 0.655, time 401.1 sec\n",
      "epoch 2, loss 0.9634, train acc 0.614, test acc 0.649, time 403.6 sec\n",
      "epoch 2, loss 0.9628, train acc 0.614, test acc 0.647, time 406.1 sec\n",
      "epoch 2, loss 0.9621, train acc 0.615, test acc 0.646, time 408.7 sec\n",
      "epoch 2, loss 0.9617, train acc 0.614, test acc 0.649, time 411.2 sec\n",
      "epoch 2, loss 0.9613, train acc 0.615, test acc 0.651, time 413.7 sec\n",
      "epoch 2, loss 0.9603, train acc 0.615, test acc 0.655, time 416.2 sec\n",
      "epoch 2, loss 0.9601, train acc 0.615, test acc 0.662, time 418.8 sec\n",
      "epoch 2, loss 0.9598, train acc 0.615, test acc 0.666, time 421.4 sec\n",
      "epoch 2, loss 0.9588, train acc 0.616, test acc 0.673, time 423.9 sec\n",
      "epoch 2, loss 0.9581, train acc 0.616, test acc 0.679, time 426.5 sec\n",
      "epoch 2, loss 0.9577, train acc 0.616, test acc 0.681, time 429.0 sec\n",
      "epoch 2, loss 0.9571, train acc 0.617, test acc 0.680, time 431.6 sec\n",
      "epoch 2, loss 0.9567, train acc 0.617, test acc 0.678, time 434.2 sec\n",
      "epoch 2, loss 0.9566, train acc 0.617, test acc 0.677, time 436.7 sec\n",
      "epoch 2, loss 0.9562, train acc 0.617, test acc 0.677, time 439.1 sec\n",
      "epoch 2, loss 0.9554, train acc 0.618, test acc 0.676, time 441.6 sec\n",
      "epoch 2, loss 0.9548, train acc 0.618, test acc 0.677, time 444.1 sec\n",
      "epoch 2, loss 0.9541, train acc 0.619, test acc 0.675, time 446.7 sec\n",
      "epoch 2, loss 0.9539, train acc 0.619, test acc 0.668, time 449.2 sec\n",
      "epoch 2, loss 0.9534, train acc 0.619, test acc 0.663, time 451.7 sec\n",
      "epoch 2, loss 0.9525, train acc 0.620, test acc 0.664, time 454.2 sec\n",
      "epoch 2, loss 0.9519, train acc 0.620, test acc 0.665, time 456.7 sec\n",
      "epoch 2, loss 0.9512, train acc 0.620, test acc 0.666, time 459.3 sec\n",
      "epoch 2, loss 0.9509, train acc 0.620, test acc 0.667, time 461.8 sec\n",
      "epoch 2, loss 0.9504, train acc 0.620, test acc 0.667, time 464.3 sec\n",
      "epoch 2, loss 0.9499, train acc 0.621, test acc 0.670, time 466.8 sec\n",
      "epoch 2, loss 0.9489, train acc 0.621, test acc 0.673, time 469.3 sec\n",
      "epoch 2, loss 0.9484, train acc 0.622, test acc 0.674, time 471.7 sec\n",
      "epoch 2, loss 0.9475, train acc 0.622, test acc 0.676, time 474.3 sec\n",
      "epoch 2, loss 0.9474, train acc 0.622, test acc 0.676, time 476.8 sec\n",
      "epoch 2, loss 0.9470, train acc 0.622, test acc 0.675, time 479.3 sec\n",
      "epoch 2, loss 0.9464, train acc 0.623, test acc 0.676, time 481.8 sec\n",
      "epoch 2, loss 0.9457, train acc 0.623, test acc 0.679, time 484.3 sec\n",
      "epoch 2, loss 0.9451, train acc 0.623, test acc 0.682, time 486.8 sec\n",
      "epoch 2, loss 0.9446, train acc 0.623, test acc 0.687, time 489.4 sec\n",
      "epoch 2, loss 0.9436, train acc 0.624, test acc 0.690, time 491.9 sec\n",
      "epoch 2, loss 0.9428, train acc 0.624, test acc 0.690, time 494.4 sec\n",
      "epoch 2, loss 0.9426, train acc 0.624, test acc 0.690, time 496.8 sec\n",
      "epoch 2, loss 0.9416, train acc 0.625, test acc 0.689, time 499.4 sec\n",
      "epoch 2, loss 0.9410, train acc 0.625, test acc 0.689, time 501.9 sec\n",
      "epoch 2, loss 0.9409, train acc 0.626, test acc 0.689, time 504.4 sec\n",
      "epoch 2, loss 0.9402, train acc 0.626, test acc 0.691, time 507.1 sec\n",
      "epoch 2, loss 0.9400, train acc 0.626, test acc 0.694, time 509.5 sec\n",
      "epoch 2, loss 0.9394, train acc 0.626, test acc 0.700, time 512.1 sec\n",
      "epoch 2, loss 0.9390, train acc 0.626, test acc 0.702, time 514.6 sec\n",
      "epoch 2, loss 0.9385, train acc 0.627, test acc 0.707, time 517.1 sec\n",
      "epoch 2, loss 0.9383, train acc 0.627, test acc 0.708, time 519.7 sec\n",
      "epoch 2, loss 0.9375, train acc 0.627, test acc 0.709, time 522.2 sec\n",
      "epoch 2, loss 0.9369, train acc 0.628, test acc 0.709, time 524.7 sec\n",
      "epoch 2, loss 0.9364, train acc 0.628, test acc 0.703, time 527.2 sec\n",
      "epoch 2, loss 0.9357, train acc 0.629, test acc 0.694, time 529.7 sec\n",
      "epoch 2, loss 0.9352, train acc 0.629, test acc 0.688, time 532.2 sec\n",
      "epoch 2, loss 0.9346, train acc 0.629, test acc 0.683, time 534.7 sec\n",
      "epoch 2, loss 0.9343, train acc 0.630, test acc 0.682, time 537.2 sec\n",
      "epoch 2, loss 0.9336, train acc 0.630, test acc 0.681, time 539.8 sec\n",
      "epoch 2, loss 0.9330, train acc 0.630, test acc 0.683, time 542.4 sec\n",
      "epoch 2, loss 0.9321, train acc 0.631, test acc 0.683, time 544.8 sec\n",
      "epoch 2, loss 0.9318, train acc 0.631, test acc 0.688, time 547.4 sec\n",
      "epoch 2, loss 0.9316, train acc 0.631, test acc 0.690, time 550.1 sec\n",
      "epoch 2, loss 0.9308, train acc 0.631, test acc 0.692, time 552.6 sec\n",
      "epoch 2, loss 0.9304, train acc 0.631, test acc 0.693, time 555.1 sec\n",
      "epoch 2, loss 0.9300, train acc 0.631, test acc 0.696, time 557.6 sec\n",
      "epoch 2, loss 0.9296, train acc 0.632, test acc 0.702, time 560.1 sec\n",
      "epoch 2, loss 0.9291, train acc 0.632, test acc 0.708, time 562.6 sec\n",
      "epoch 2, loss 0.9282, train acc 0.633, test acc 0.711, time 565.2 sec\n",
      "epoch 2, loss 0.9278, train acc 0.633, test acc 0.710, time 567.7 sec\n",
      "epoch 2, loss 0.9271, train acc 0.633, test acc 0.707, time 570.2 sec\n",
      "epoch 2, loss 0.9269, train acc 0.633, test acc 0.707, time 572.7 sec\n",
      "epoch 2, loss 0.9263, train acc 0.634, test acc 0.706, time 575.2 sec\n",
      "epoch 2, loss 0.9258, train acc 0.634, test acc 0.700, time 578.2 sec\n",
      "epoch 2, loss 0.9251, train acc 0.634, test acc 0.695, time 580.7 sec\n",
      "epoch 2, loss 0.9246, train acc 0.635, test acc 0.693, time 583.2 sec\n",
      "epoch 2, loss 0.9242, train acc 0.635, test acc 0.694, time 585.7 sec\n",
      "epoch 2, loss 0.9233, train acc 0.635, test acc 0.693, time 588.3 sec\n",
      "epoch 2, loss 0.9226, train acc 0.636, test acc 0.697, time 590.9 sec\n",
      "epoch 2, loss 0.9222, train acc 0.636, test acc 0.701, time 593.3 sec\n",
      "epoch 3, loss 0.7574, train acc 0.688, test acc 0.703, time 2.5 sec\n",
      "epoch 3, loss 0.7879, train acc 0.686, test acc 0.706, time 5.0 sec\n",
      "epoch 3, loss 0.7947, train acc 0.701, test acc 0.709, time 7.5 sec\n",
      "epoch 3, loss 0.7873, train acc 0.716, test acc 0.708, time 10.1 sec\n",
      "epoch 3, loss 0.7758, train acc 0.721, test acc 0.706, time 12.6 sec\n",
      "epoch 3, loss 0.7787, train acc 0.719, test acc 0.707, time 15.2 sec\n",
      "epoch 3, loss 0.7699, train acc 0.722, test acc 0.714, time 17.7 sec\n",
      "epoch 3, loss 0.7784, train acc 0.718, test acc 0.717, time 20.2 sec\n",
      "epoch 3, loss 0.7797, train acc 0.720, test acc 0.717, time 22.7 sec\n",
      "epoch 3, loss 0.7831, train acc 0.723, test acc 0.717, time 25.2 sec\n",
      "epoch 3, loss 0.7845, train acc 0.722, test acc 0.721, time 27.7 sec\n",
      "epoch 3, loss 0.7812, train acc 0.723, test acc 0.722, time 30.2 sec\n",
      "epoch 3, loss 0.7843, train acc 0.721, test acc 0.721, time 32.7 sec\n",
      "epoch 3, loss 0.7927, train acc 0.717, test acc 0.721, time 35.2 sec\n",
      "epoch 3, loss 0.7965, train acc 0.715, test acc 0.721, time 37.7 sec\n",
      "epoch 3, loss 0.7985, train acc 0.713, test acc 0.722, time 40.2 sec\n",
      "epoch 3, loss 0.8034, train acc 0.710, test acc 0.720, time 43.6 sec\n",
      "epoch 3, loss 0.8051, train acc 0.710, test acc 0.716, time 47.1 sec\n",
      "epoch 3, loss 0.7996, train acc 0.713, test acc 0.710, time 49.7 sec\n",
      "epoch 3, loss 0.7941, train acc 0.715, test acc 0.706, time 52.2 sec\n",
      "epoch 3, loss 0.7909, train acc 0.716, test acc 0.706, time 54.7 sec\n",
      "epoch 3, loss 0.7906, train acc 0.716, test acc 0.707, time 57.4 sec\n",
      "epoch 3, loss 0.7876, train acc 0.717, test acc 0.713, time 59.9 sec\n",
      "epoch 3, loss 0.7883, train acc 0.719, test acc 0.721, time 62.4 sec\n",
      "epoch 3, loss 0.7894, train acc 0.718, test acc 0.725, time 64.9 sec\n",
      "epoch 3, loss 0.7890, train acc 0.717, test acc 0.727, time 67.5 sec\n",
      "epoch 3, loss 0.7849, train acc 0.718, test acc 0.728, time 70.0 sec\n",
      "epoch 3, loss 0.7814, train acc 0.719, test acc 0.726, time 72.5 sec\n",
      "epoch 3, loss 0.7809, train acc 0.719, test acc 0.726, time 75.0 sec\n",
      "epoch 3, loss 0.7804, train acc 0.720, test acc 0.723, time 77.7 sec\n",
      "epoch 3, loss 0.7775, train acc 0.721, test acc 0.720, time 81.0 sec\n",
      "epoch 3, loss 0.7747, train acc 0.721, test acc 0.719, time 83.6 sec\n",
      "epoch 3, loss 0.7720, train acc 0.723, test acc 0.719, time 86.1 sec\n",
      "epoch 3, loss 0.7707, train acc 0.723, test acc 0.718, time 88.7 sec\n",
      "epoch 3, loss 0.7708, train acc 0.723, test acc 0.715, time 91.2 sec\n",
      "epoch 3, loss 0.7687, train acc 0.723, test acc 0.717, time 93.7 sec\n",
      "epoch 3, loss 0.7718, train acc 0.722, test acc 0.721, time 96.2 sec\n",
      "epoch 3, loss 0.7709, train acc 0.722, test acc 0.726, time 98.8 sec\n",
      "epoch 3, loss 0.7706, train acc 0.723, test acc 0.731, time 101.3 sec\n",
      "epoch 3, loss 0.7704, train acc 0.723, test acc 0.729, time 103.9 sec\n",
      "epoch 3, loss 0.7690, train acc 0.724, test acc 0.725, time 106.4 sec\n",
      "epoch 3, loss 0.7691, train acc 0.724, test acc 0.723, time 108.9 sec\n",
      "epoch 3, loss 0.7703, train acc 0.724, test acc 0.724, time 111.5 sec\n",
      "epoch 3, loss 0.7685, train acc 0.725, test acc 0.726, time 114.0 sec\n",
      "epoch 3, loss 0.7679, train acc 0.725, test acc 0.731, time 116.6 sec\n",
      "epoch 3, loss 0.7667, train acc 0.725, test acc 0.732, time 119.1 sec\n",
      "epoch 3, loss 0.7668, train acc 0.725, test acc 0.725, time 121.7 sec\n",
      "epoch 3, loss 0.7664, train acc 0.725, test acc 0.720, time 124.2 sec\n",
      "epoch 3, loss 0.7662, train acc 0.725, test acc 0.717, time 126.7 sec\n",
      "epoch 3, loss 0.7658, train acc 0.725, test acc 0.724, time 129.3 sec\n",
      "epoch 3, loss 0.7666, train acc 0.724, test acc 0.725, time 131.8 sec\n",
      "epoch 3, loss 0.7653, train acc 0.725, test acc 0.722, time 134.3 sec\n",
      "epoch 3, loss 0.7657, train acc 0.724, test acc 0.721, time 137.0 sec\n",
      "epoch 3, loss 0.7660, train acc 0.724, test acc 0.721, time 139.5 sec\n",
      "epoch 3, loss 0.7660, train acc 0.724, test acc 0.722, time 142.1 sec\n",
      "epoch 3, loss 0.7648, train acc 0.725, test acc 0.726, time 144.6 sec\n",
      "epoch 3, loss 0.7640, train acc 0.725, test acc 0.729, time 147.2 sec\n",
      "epoch 3, loss 0.7647, train acc 0.724, test acc 0.734, time 149.7 sec\n",
      "epoch 3, loss 0.7651, train acc 0.723, test acc 0.734, time 152.2 sec\n",
      "epoch 3, loss 0.7662, train acc 0.723, test acc 0.732, time 154.8 sec\n",
      "epoch 3, loss 0.7656, train acc 0.723, test acc 0.725, time 157.4 sec\n",
      "epoch 3, loss 0.7660, train acc 0.723, test acc 0.724, time 159.9 sec\n",
      "epoch 3, loss 0.7653, train acc 0.724, test acc 0.723, time 162.4 sec\n",
      "epoch 3, loss 0.7643, train acc 0.724, test acc 0.723, time 165.3 sec\n",
      "epoch 3, loss 0.7642, train acc 0.724, test acc 0.722, time 168.2 sec\n",
      "epoch 3, loss 0.7642, train acc 0.723, test acc 0.719, time 171.5 sec\n",
      "epoch 3, loss 0.7652, train acc 0.723, test acc 0.718, time 174.7 sec\n",
      "epoch 3, loss 0.7647, train acc 0.724, test acc 0.719, time 177.2 sec\n",
      "epoch 3, loss 0.7656, train acc 0.723, test acc 0.722, time 179.8 sec\n",
      "epoch 3, loss 0.7661, train acc 0.722, test acc 0.724, time 182.4 sec\n",
      "epoch 3, loss 0.7647, train acc 0.723, test acc 0.726, time 184.9 sec\n",
      "epoch 3, loss 0.7646, train acc 0.722, test acc 0.727, time 187.5 sec\n",
      "epoch 3, loss 0.7645, train acc 0.723, test acc 0.728, time 190.0 sec\n",
      "epoch 3, loss 0.7637, train acc 0.723, test acc 0.732, time 192.5 sec\n",
      "epoch 3, loss 0.7628, train acc 0.723, test acc 0.734, time 195.1 sec\n",
      "epoch 3, loss 0.7617, train acc 0.723, test acc 0.735, time 197.7 sec\n",
      "epoch 3, loss 0.7612, train acc 0.723, test acc 0.732, time 200.3 sec\n",
      "epoch 3, loss 0.7610, train acc 0.723, test acc 0.733, time 202.8 sec\n",
      "epoch 3, loss 0.7605, train acc 0.724, test acc 0.734, time 205.3 sec\n",
      "epoch 3, loss 0.7592, train acc 0.724, test acc 0.734, time 207.9 sec\n",
      "epoch 3, loss 0.7592, train acc 0.724, test acc 0.734, time 210.5 sec\n",
      "epoch 3, loss 0.7592, train acc 0.724, test acc 0.735, time 213.1 sec\n",
      "epoch 3, loss 0.7592, train acc 0.724, test acc 0.735, time 216.3 sec\n",
      "epoch 3, loss 0.7585, train acc 0.725, test acc 0.737, time 219.3 sec\n",
      "epoch 3, loss 0.7590, train acc 0.724, test acc 0.736, time 222.2 sec\n",
      "epoch 3, loss 0.7587, train acc 0.724, test acc 0.734, time 224.7 sec\n",
      "epoch 3, loss 0.7578, train acc 0.725, test acc 0.731, time 227.2 sec\n",
      "epoch 3, loss 0.7581, train acc 0.725, test acc 0.725, time 229.7 sec\n",
      "epoch 3, loss 0.7576, train acc 0.725, test acc 0.723, time 232.2 sec\n",
      "epoch 3, loss 0.7576, train acc 0.724, test acc 0.724, time 234.8 sec\n",
      "epoch 3, loss 0.7565, train acc 0.724, test acc 0.727, time 237.3 sec\n",
      "epoch 3, loss 0.7561, train acc 0.724, test acc 0.727, time 239.8 sec\n",
      "epoch 3, loss 0.7557, train acc 0.724, test acc 0.727, time 242.3 sec\n",
      "epoch 3, loss 0.7551, train acc 0.724, test acc 0.728, time 244.8 sec\n",
      "epoch 3, loss 0.7539, train acc 0.725, test acc 0.728, time 247.3 sec\n",
      "epoch 3, loss 0.7533, train acc 0.725, test acc 0.729, time 249.9 sec\n",
      "epoch 3, loss 0.7525, train acc 0.725, test acc 0.731, time 252.4 sec\n",
      "epoch 3, loss 0.7523, train acc 0.725, test acc 0.734, time 254.9 sec\n",
      "epoch 3, loss 0.7523, train acc 0.725, test acc 0.736, time 257.5 sec\n",
      "epoch 3, loss 0.7518, train acc 0.725, test acc 0.736, time 260.0 sec\n",
      "epoch 3, loss 0.7513, train acc 0.725, test acc 0.736, time 262.6 sec\n",
      "epoch 3, loss 0.7502, train acc 0.726, test acc 0.737, time 265.1 sec\n",
      "epoch 3, loss 0.7497, train acc 0.726, test acc 0.738, time 267.6 sec\n",
      "epoch 3, loss 0.7497, train acc 0.726, test acc 0.740, time 270.1 sec\n",
      "epoch 3, loss 0.7495, train acc 0.726, test acc 0.740, time 272.6 sec\n",
      "epoch 3, loss 0.7494, train acc 0.727, test acc 0.739, time 275.2 sec\n",
      "epoch 3, loss 0.7497, train acc 0.726, test acc 0.740, time 277.7 sec\n",
      "epoch 3, loss 0.7496, train acc 0.726, test acc 0.739, time 280.2 sec\n",
      "epoch 3, loss 0.7485, train acc 0.727, test acc 0.738, time 282.7 sec\n",
      "epoch 3, loss 0.7474, train acc 0.727, test acc 0.739, time 285.2 sec\n",
      "epoch 3, loss 0.7465, train acc 0.728, test acc 0.737, time 287.8 sec\n",
      "epoch 3, loss 0.7462, train acc 0.728, test acc 0.736, time 290.2 sec\n",
      "epoch 3, loss 0.7465, train acc 0.728, test acc 0.736, time 292.7 sec\n",
      "epoch 3, loss 0.7467, train acc 0.727, test acc 0.735, time 295.2 sec\n",
      "epoch 3, loss 0.7463, train acc 0.728, test acc 0.733, time 297.7 sec\n",
      "epoch 3, loss 0.7462, train acc 0.728, test acc 0.729, time 300.2 sec\n",
      "epoch 3, loss 0.7462, train acc 0.727, test acc 0.730, time 302.8 sec\n",
      "epoch 3, loss 0.7454, train acc 0.728, test acc 0.730, time 305.4 sec\n",
      "epoch 3, loss 0.7447, train acc 0.728, test acc 0.732, time 307.9 sec\n",
      "epoch 3, loss 0.7443, train acc 0.728, test acc 0.736, time 310.4 sec\n",
      "epoch 3, loss 0.7443, train acc 0.728, test acc 0.740, time 313.0 sec\n",
      "epoch 3, loss 0.7428, train acc 0.728, test acc 0.743, time 315.5 sec\n",
      "epoch 3, loss 0.7422, train acc 0.728, test acc 0.743, time 318.1 sec\n",
      "epoch 3, loss 0.7417, train acc 0.729, test acc 0.742, time 320.6 sec\n",
      "epoch 3, loss 0.7419, train acc 0.728, test acc 0.740, time 323.1 sec\n",
      "epoch 3, loss 0.7414, train acc 0.728, test acc 0.740, time 325.6 sec\n",
      "epoch 3, loss 0.7408, train acc 0.728, test acc 0.741, time 328.2 sec\n",
      "epoch 3, loss 0.7410, train acc 0.728, test acc 0.739, time 330.7 sec\n",
      "epoch 3, loss 0.7398, train acc 0.728, test acc 0.740, time 333.2 sec\n",
      "epoch 3, loss 0.7393, train acc 0.729, test acc 0.740, time 335.7 sec\n",
      "epoch 3, loss 0.7392, train acc 0.729, test acc 0.740, time 338.2 sec\n",
      "epoch 3, loss 0.7388, train acc 0.729, test acc 0.741, time 340.7 sec\n",
      "epoch 3, loss 0.7386, train acc 0.729, test acc 0.743, time 343.2 sec\n",
      "epoch 3, loss 0.7376, train acc 0.729, test acc 0.743, time 345.7 sec\n",
      "epoch 3, loss 0.7376, train acc 0.729, test acc 0.740, time 348.2 sec\n",
      "epoch 3, loss 0.7371, train acc 0.729, test acc 0.737, time 350.7 sec\n",
      "epoch 3, loss 0.7372, train acc 0.729, test acc 0.735, time 353.2 sec\n",
      "epoch 3, loss 0.7368, train acc 0.729, test acc 0.735, time 355.8 sec\n",
      "epoch 3, loss 0.7366, train acc 0.729, test acc 0.734, time 358.3 sec\n",
      "epoch 3, loss 0.7364, train acc 0.729, test acc 0.734, time 360.9 sec\n",
      "epoch 3, loss 0.7357, train acc 0.729, test acc 0.737, time 363.4 sec\n",
      "epoch 3, loss 0.7352, train acc 0.729, test acc 0.738, time 365.9 sec\n",
      "epoch 3, loss 0.7344, train acc 0.730, test acc 0.742, time 368.5 sec\n",
      "epoch 3, loss 0.7338, train acc 0.730, test acc 0.743, time 371.0 sec\n",
      "epoch 3, loss 0.7334, train acc 0.730, test acc 0.741, time 373.5 sec\n",
      "epoch 3, loss 0.7330, train acc 0.730, test acc 0.739, time 376.0 sec\n",
      "epoch 3, loss 0.7331, train acc 0.730, test acc 0.740, time 378.5 sec\n",
      "epoch 3, loss 0.7329, train acc 0.730, test acc 0.743, time 381.1 sec\n",
      "epoch 3, loss 0.7325, train acc 0.730, test acc 0.743, time 383.6 sec\n",
      "epoch 3, loss 0.7325, train acc 0.730, test acc 0.742, time 386.2 sec\n",
      "epoch 3, loss 0.7326, train acc 0.730, test acc 0.741, time 388.7 sec\n",
      "epoch 3, loss 0.7321, train acc 0.730, test acc 0.742, time 391.2 sec\n",
      "epoch 3, loss 0.7317, train acc 0.730, test acc 0.743, time 393.7 sec\n",
      "epoch 3, loss 0.7309, train acc 0.730, test acc 0.745, time 396.2 sec\n",
      "epoch 3, loss 0.7306, train acc 0.730, test acc 0.745, time 398.7 sec\n",
      "epoch 3, loss 0.7308, train acc 0.730, test acc 0.742, time 401.2 sec\n",
      "epoch 3, loss 0.7304, train acc 0.731, test acc 0.740, time 403.7 sec\n",
      "epoch 3, loss 0.7300, train acc 0.731, test acc 0.740, time 406.2 sec\n",
      "epoch 3, loss 0.7298, train acc 0.731, test acc 0.739, time 408.8 sec\n",
      "epoch 3, loss 0.7294, train acc 0.731, test acc 0.741, time 411.3 sec\n",
      "epoch 3, loss 0.7288, train acc 0.731, test acc 0.741, time 413.8 sec\n",
      "epoch 3, loss 0.7284, train acc 0.731, test acc 0.742, time 416.2 sec\n",
      "epoch 3, loss 0.7284, train acc 0.731, test acc 0.743, time 418.7 sec\n",
      "epoch 3, loss 0.7280, train acc 0.731, test acc 0.741, time 421.3 sec\n",
      "epoch 3, loss 0.7273, train acc 0.732, test acc 0.741, time 423.8 sec\n",
      "epoch 3, loss 0.7269, train acc 0.732, test acc 0.742, time 426.4 sec\n",
      "epoch 3, loss 0.7264, train acc 0.732, test acc 0.741, time 429.0 sec\n",
      "epoch 3, loss 0.7260, train acc 0.732, test acc 0.741, time 431.5 sec\n",
      "epoch 3, loss 0.7260, train acc 0.732, test acc 0.742, time 434.0 sec\n",
      "epoch 3, loss 0.7256, train acc 0.732, test acc 0.743, time 436.6 sec\n",
      "epoch 3, loss 0.7251, train acc 0.732, test acc 0.745, time 439.1 sec\n",
      "epoch 3, loss 0.7248, train acc 0.732, test acc 0.745, time 441.6 sec\n",
      "epoch 3, loss 0.7240, train acc 0.732, test acc 0.746, time 444.1 sec\n",
      "epoch 3, loss 0.7233, train acc 0.733, test acc 0.747, time 446.7 sec\n",
      "epoch 3, loss 0.7231, train acc 0.733, test acc 0.748, time 449.2 sec\n",
      "epoch 3, loss 0.7228, train acc 0.733, test acc 0.747, time 451.6 sec\n",
      "epoch 3, loss 0.7223, train acc 0.733, test acc 0.747, time 454.1 sec\n",
      "epoch 3, loss 0.7223, train acc 0.733, test acc 0.746, time 456.7 sec\n",
      "epoch 3, loss 0.7219, train acc 0.733, test acc 0.744, time 459.3 sec\n",
      "epoch 3, loss 0.7211, train acc 0.733, test acc 0.745, time 461.8 sec\n",
      "epoch 3, loss 0.7205, train acc 0.734, test acc 0.741, time 464.3 sec\n",
      "epoch 3, loss 0.7197, train acc 0.734, test acc 0.740, time 466.8 sec\n",
      "epoch 3, loss 0.7196, train acc 0.734, test acc 0.738, time 469.3 sec\n",
      "epoch 3, loss 0.7191, train acc 0.734, test acc 0.738, time 471.8 sec\n",
      "epoch 3, loss 0.7189, train acc 0.734, test acc 0.742, time 474.4 sec\n",
      "epoch 3, loss 0.7187, train acc 0.734, test acc 0.744, time 476.9 sec\n",
      "epoch 3, loss 0.7182, train acc 0.734, test acc 0.743, time 479.4 sec\n",
      "epoch 3, loss 0.7180, train acc 0.734, test acc 0.746, time 481.9 sec\n",
      "epoch 3, loss 0.7178, train acc 0.734, test acc 0.748, time 484.4 sec\n",
      "epoch 3, loss 0.7174, train acc 0.734, test acc 0.748, time 487.0 sec\n",
      "epoch 3, loss 0.7168, train acc 0.735, test acc 0.748, time 489.5 sec\n",
      "epoch 3, loss 0.7166, train acc 0.735, test acc 0.748, time 492.0 sec\n",
      "epoch 3, loss 0.7163, train acc 0.735, test acc 0.747, time 494.5 sec\n",
      "epoch 3, loss 0.7158, train acc 0.735, test acc 0.746, time 497.0 sec\n",
      "epoch 3, loss 0.7159, train acc 0.735, test acc 0.745, time 499.6 sec\n",
      "epoch 3, loss 0.7160, train acc 0.735, test acc 0.746, time 502.1 sec\n",
      "epoch 3, loss 0.7151, train acc 0.735, test acc 0.745, time 504.6 sec\n",
      "epoch 3, loss 0.7148, train acc 0.735, test acc 0.745, time 507.1 sec\n",
      "epoch 3, loss 0.7146, train acc 0.735, test acc 0.743, time 509.6 sec\n",
      "epoch 3, loss 0.7143, train acc 0.735, test acc 0.744, time 512.3 sec\n",
      "epoch 3, loss 0.7136, train acc 0.735, test acc 0.745, time 514.8 sec\n",
      "epoch 3, loss 0.7135, train acc 0.735, test acc 0.747, time 517.4 sec\n",
      "epoch 3, loss 0.7133, train acc 0.736, test acc 0.748, time 519.9 sec\n",
      "epoch 3, loss 0.7129, train acc 0.736, test acc 0.748, time 522.4 sec\n",
      "epoch 3, loss 0.7127, train acc 0.736, test acc 0.749, time 525.1 sec\n",
      "epoch 3, loss 0.7120, train acc 0.736, test acc 0.748, time 527.6 sec\n",
      "epoch 3, loss 0.7117, train acc 0.736, test acc 0.749, time 530.1 sec\n",
      "epoch 3, loss 0.7112, train acc 0.736, test acc 0.749, time 532.6 sec\n",
      "epoch 3, loss 0.7106, train acc 0.736, test acc 0.749, time 535.2 sec\n",
      "epoch 3, loss 0.7103, train acc 0.737, test acc 0.748, time 537.7 sec\n",
      "epoch 3, loss 0.7097, train acc 0.737, test acc 0.747, time 540.3 sec\n",
      "epoch 3, loss 0.7096, train acc 0.737, test acc 0.747, time 542.8 sec\n",
      "epoch 3, loss 0.7095, train acc 0.737, test acc 0.746, time 545.3 sec\n",
      "epoch 3, loss 0.7092, train acc 0.737, test acc 0.746, time 547.9 sec\n",
      "epoch 3, loss 0.7090, train acc 0.737, test acc 0.747, time 550.4 sec\n",
      "epoch 3, loss 0.7087, train acc 0.737, test acc 0.745, time 553.0 sec\n",
      "epoch 3, loss 0.7089, train acc 0.737, test acc 0.746, time 555.5 sec\n",
      "epoch 3, loss 0.7085, train acc 0.737, test acc 0.746, time 558.1 sec\n",
      "epoch 3, loss 0.7082, train acc 0.737, test acc 0.744, time 560.6 sec\n",
      "epoch 3, loss 0.7079, train acc 0.737, test acc 0.745, time 563.1 sec\n",
      "epoch 3, loss 0.7076, train acc 0.737, test acc 0.744, time 565.7 sec\n",
      "epoch 3, loss 0.7074, train acc 0.737, test acc 0.747, time 568.2 sec\n",
      "epoch 3, loss 0.7070, train acc 0.737, test acc 0.748, time 570.7 sec\n",
      "epoch 3, loss 0.7067, train acc 0.737, test acc 0.748, time 573.2 sec\n",
      "epoch 3, loss 0.7061, train acc 0.737, test acc 0.748, time 575.7 sec\n",
      "epoch 3, loss 0.7053, train acc 0.738, test acc 0.748, time 578.3 sec\n",
      "epoch 3, loss 0.7051, train acc 0.738, test acc 0.750, time 580.8 sec\n",
      "epoch 3, loss 0.7049, train acc 0.738, test acc 0.750, time 583.3 sec\n",
      "epoch 3, loss 0.7042, train acc 0.738, test acc 0.748, time 585.8 sec\n",
      "epoch 3, loss 0.7040, train acc 0.738, test acc 0.748, time 588.5 sec\n",
      "epoch 3, loss 0.7037, train acc 0.738, test acc 0.748, time 591.1 sec\n",
      "epoch 3, loss 0.7031, train acc 0.738, test acc 0.749, time 593.6 sec\n",
      "epoch 3, loss 0.7029, train acc 0.738, test acc 0.749, time 596.1 sec\n",
      "epoch 3, loss 0.7025, train acc 0.738, test acc 0.749, time 598.6 sec\n",
      "epoch 3, loss 0.7024, train acc 0.738, test acc 0.749, time 601.1 sec\n",
      "epoch 4, loss 0.6678, train acc 0.738, test acc 0.744, time 2.5 sec\n",
      "epoch 4, loss 0.6912, train acc 0.727, test acc 0.741, time 5.0 sec\n",
      "epoch 4, loss 0.6664, train acc 0.738, test acc 0.746, time 7.5 sec\n",
      "epoch 4, loss 0.6653, train acc 0.744, test acc 0.747, time 10.0 sec\n",
      "epoch 4, loss 0.6601, train acc 0.749, test acc 0.751, time 12.5 sec\n",
      "epoch 4, loss 0.6470, train acc 0.755, test acc 0.749, time 15.1 sec\n",
      "epoch 4, loss 0.6536, train acc 0.748, test acc 0.751, time 17.7 sec\n",
      "epoch 4, loss 0.6439, train acc 0.752, test acc 0.749, time 20.2 sec\n",
      "epoch 4, loss 0.6473, train acc 0.753, test acc 0.751, time 22.7 sec\n",
      "epoch 4, loss 0.6379, train acc 0.756, test acc 0.752, time 25.2 sec\n",
      "epoch 4, loss 0.6405, train acc 0.755, test acc 0.753, time 27.7 sec\n",
      "epoch 4, loss 0.6367, train acc 0.757, test acc 0.748, time 30.2 sec\n",
      "epoch 4, loss 0.6270, train acc 0.763, test acc 0.750, time 32.8 sec\n",
      "epoch 4, loss 0.6273, train acc 0.763, test acc 0.749, time 35.3 sec\n",
      "epoch 4, loss 0.6279, train acc 0.764, test acc 0.748, time 37.8 sec\n",
      "epoch 4, loss 0.6268, train acc 0.764, test acc 0.747, time 40.3 sec\n",
      "epoch 4, loss 0.6314, train acc 0.762, test acc 0.745, time 42.7 sec\n",
      "epoch 4, loss 0.6304, train acc 0.762, test acc 0.745, time 45.3 sec\n",
      "epoch 4, loss 0.6323, train acc 0.759, test acc 0.746, time 47.8 sec\n",
      "epoch 4, loss 0.6321, train acc 0.761, test acc 0.747, time 50.3 sec\n",
      "epoch 4, loss 0.6365, train acc 0.759, test acc 0.748, time 52.9 sec\n",
      "epoch 4, loss 0.6384, train acc 0.757, test acc 0.749, time 55.4 sec\n",
      "epoch 4, loss 0.6347, train acc 0.760, test acc 0.750, time 57.9 sec\n",
      "epoch 4, loss 0.6355, train acc 0.759, test acc 0.751, time 60.4 sec\n",
      "epoch 4, loss 0.6364, train acc 0.758, test acc 0.751, time 62.9 sec\n",
      "epoch 4, loss 0.6382, train acc 0.756, test acc 0.750, time 65.5 sec\n",
      "epoch 4, loss 0.6406, train acc 0.755, test acc 0.752, time 68.1 sec\n",
      "epoch 4, loss 0.6429, train acc 0.755, test acc 0.753, time 70.6 sec\n",
      "epoch 4, loss 0.6399, train acc 0.756, test acc 0.753, time 73.2 sec\n",
      "epoch 4, loss 0.6410, train acc 0.755, test acc 0.754, time 75.7 sec\n",
      "epoch 4, loss 0.6387, train acc 0.757, test acc 0.754, time 78.2 sec\n",
      "epoch 4, loss 0.6406, train acc 0.757, test acc 0.752, time 80.7 sec\n",
      "epoch 4, loss 0.6397, train acc 0.757, test acc 0.753, time 83.2 sec\n",
      "epoch 4, loss 0.6390, train acc 0.757, test acc 0.753, time 85.8 sec\n",
      "epoch 4, loss 0.6388, train acc 0.756, test acc 0.753, time 88.3 sec\n",
      "epoch 4, loss 0.6368, train acc 0.757, test acc 0.753, time 90.8 sec\n",
      "epoch 4, loss 0.6376, train acc 0.757, test acc 0.753, time 93.3 sec\n",
      "epoch 4, loss 0.6382, train acc 0.756, test acc 0.752, time 95.8 sec\n",
      "epoch 4, loss 0.6371, train acc 0.756, test acc 0.751, time 98.3 sec\n",
      "epoch 4, loss 0.6360, train acc 0.757, test acc 0.748, time 100.8 sec\n",
      "epoch 4, loss 0.6340, train acc 0.757, test acc 0.749, time 103.3 sec\n",
      "epoch 4, loss 0.6315, train acc 0.759, test acc 0.749, time 105.8 sec\n",
      "epoch 4, loss 0.6314, train acc 0.758, test acc 0.750, time 108.3 sec\n",
      "epoch 4, loss 0.6315, train acc 0.758, test acc 0.751, time 110.8 sec\n",
      "epoch 4, loss 0.6312, train acc 0.758, test acc 0.753, time 113.4 sec\n",
      "epoch 4, loss 0.6311, train acc 0.758, test acc 0.752, time 115.9 sec\n",
      "epoch 4, loss 0.6320, train acc 0.758, test acc 0.750, time 118.4 sec\n",
      "epoch 4, loss 0.6314, train acc 0.757, test acc 0.751, time 120.9 sec\n",
      "epoch 4, loss 0.6309, train acc 0.757, test acc 0.753, time 123.4 sec\n",
      "epoch 4, loss 0.6296, train acc 0.758, test acc 0.755, time 126.0 sec\n",
      "epoch 4, loss 0.6289, train acc 0.758, test acc 0.756, time 128.5 sec\n",
      "epoch 4, loss 0.6271, train acc 0.759, test acc 0.756, time 131.0 sec\n",
      "epoch 4, loss 0.6279, train acc 0.759, test acc 0.756, time 133.5 sec\n",
      "epoch 4, loss 0.6271, train acc 0.759, test acc 0.752, time 136.1 sec\n",
      "epoch 4, loss 0.6287, train acc 0.758, test acc 0.750, time 138.6 sec\n",
      "epoch 4, loss 0.6287, train acc 0.758, test acc 0.751, time 141.1 sec\n",
      "epoch 4, loss 0.6291, train acc 0.758, test acc 0.751, time 143.6 sec\n",
      "epoch 4, loss 0.6285, train acc 0.758, test acc 0.751, time 146.1 sec\n",
      "epoch 4, loss 0.6301, train acc 0.757, test acc 0.753, time 148.6 sec\n",
      "epoch 4, loss 0.6306, train acc 0.757, test acc 0.753, time 151.2 sec\n",
      "epoch 4, loss 0.6312, train acc 0.757, test acc 0.753, time 153.7 sec\n",
      "epoch 4, loss 0.6319, train acc 0.757, test acc 0.756, time 156.2 sec\n",
      "epoch 4, loss 0.6306, train acc 0.757, test acc 0.754, time 158.7 sec\n",
      "epoch 4, loss 0.6294, train acc 0.758, test acc 0.756, time 161.2 sec\n",
      "epoch 4, loss 0.6295, train acc 0.757, test acc 0.758, time 163.8 sec\n",
      "epoch 4, loss 0.6289, train acc 0.757, test acc 0.757, time 166.3 sec\n",
      "epoch 4, loss 0.6304, train acc 0.756, test acc 0.758, time 168.8 sec\n",
      "epoch 4, loss 0.6299, train acc 0.756, test acc 0.758, time 171.3 sec\n",
      "epoch 4, loss 0.6299, train acc 0.756, test acc 0.756, time 173.8 sec\n",
      "epoch 4, loss 0.6299, train acc 0.756, test acc 0.754, time 176.3 sec\n",
      "epoch 4, loss 0.6297, train acc 0.756, test acc 0.755, time 178.8 sec\n",
      "epoch 4, loss 0.6286, train acc 0.756, test acc 0.755, time 181.3 sec\n",
      "epoch 4, loss 0.6278, train acc 0.757, test acc 0.755, time 183.8 sec\n",
      "epoch 4, loss 0.6265, train acc 0.757, test acc 0.753, time 186.4 sec\n",
      "epoch 4, loss 0.6262, train acc 0.757, test acc 0.753, time 189.0 sec\n",
      "epoch 4, loss 0.6257, train acc 0.757, test acc 0.750, time 191.6 sec\n",
      "epoch 4, loss 0.6255, train acc 0.758, test acc 0.749, time 194.1 sec\n",
      "epoch 4, loss 0.6254, train acc 0.758, test acc 0.748, time 196.6 sec\n",
      "epoch 4, loss 0.6258, train acc 0.758, test acc 0.748, time 199.1 sec\n",
      "epoch 4, loss 0.6255, train acc 0.758, test acc 0.748, time 201.6 sec\n",
      "epoch 4, loss 0.6251, train acc 0.757, test acc 0.750, time 204.9 sec\n",
      "epoch 4, loss 0.6249, train acc 0.757, test acc 0.753, time 207.6 sec\n",
      "epoch 4, loss 0.6247, train acc 0.757, test acc 0.754, time 210.1 sec\n",
      "epoch 4, loss 0.6253, train acc 0.757, test acc 0.755, time 212.6 sec\n",
      "epoch 4, loss 0.6259, train acc 0.756, test acc 0.758, time 215.1 sec\n",
      "epoch 4, loss 0.6254, train acc 0.756, test acc 0.764, time 217.7 sec\n",
      "epoch 4, loss 0.6247, train acc 0.756, test acc 0.763, time 220.2 sec\n",
      "epoch 4, loss 0.6252, train acc 0.756, test acc 0.762, time 222.8 sec\n",
      "epoch 4, loss 0.6256, train acc 0.756, test acc 0.761, time 225.3 sec\n",
      "epoch 4, loss 0.6253, train acc 0.756, test acc 0.758, time 227.8 sec\n",
      "epoch 4, loss 0.6252, train acc 0.756, test acc 0.754, time 230.4 sec\n",
      "epoch 4, loss 0.6252, train acc 0.756, test acc 0.753, time 232.9 sec\n",
      "epoch 4, loss 0.6242, train acc 0.757, test acc 0.754, time 235.5 sec\n",
      "epoch 4, loss 0.6244, train acc 0.757, test acc 0.754, time 238.0 sec\n",
      "epoch 4, loss 0.6255, train acc 0.757, test acc 0.756, time 240.5 sec\n",
      "epoch 4, loss 0.6257, train acc 0.756, test acc 0.757, time 243.1 sec\n",
      "epoch 4, loss 0.6264, train acc 0.756, test acc 0.759, time 245.6 sec\n",
      "epoch 4, loss 0.6256, train acc 0.756, test acc 0.759, time 248.1 sec\n",
      "epoch 4, loss 0.6255, train acc 0.756, test acc 0.761, time 250.6 sec\n",
      "epoch 4, loss 0.6266, train acc 0.756, test acc 0.761, time 253.1 sec\n",
      "epoch 4, loss 0.6270, train acc 0.755, test acc 0.760, time 255.7 sec\n",
      "epoch 4, loss 0.6266, train acc 0.756, test acc 0.760, time 258.2 sec\n",
      "epoch 4, loss 0.6267, train acc 0.756, test acc 0.759, time 260.7 sec\n",
      "epoch 4, loss 0.6260, train acc 0.756, test acc 0.760, time 263.2 sec\n",
      "epoch 4, loss 0.6260, train acc 0.756, test acc 0.761, time 265.7 sec\n",
      "epoch 4, loss 0.6264, train acc 0.756, test acc 0.761, time 268.2 sec\n",
      "epoch 4, loss 0.6263, train acc 0.756, test acc 0.760, time 270.8 sec\n",
      "epoch 4, loss 0.6261, train acc 0.756, test acc 0.758, time 273.3 sec\n",
      "epoch 4, loss 0.6260, train acc 0.756, test acc 0.760, time 275.8 sec\n",
      "epoch 4, loss 0.6253, train acc 0.757, test acc 0.761, time 278.3 sec\n",
      "epoch 4, loss 0.6255, train acc 0.756, test acc 0.762, time 280.8 sec\n",
      "epoch 4, loss 0.6262, train acc 0.756, test acc 0.761, time 283.4 sec\n",
      "epoch 4, loss 0.6266, train acc 0.756, test acc 0.758, time 286.0 sec\n",
      "epoch 4, loss 0.6270, train acc 0.756, test acc 0.755, time 288.5 sec\n",
      "epoch 4, loss 0.6263, train acc 0.756, test acc 0.754, time 291.0 sec\n",
      "epoch 4, loss 0.6272, train acc 0.756, test acc 0.756, time 293.5 sec\n",
      "epoch 4, loss 0.6268, train acc 0.756, test acc 0.758, time 296.1 sec\n",
      "epoch 4, loss 0.6264, train acc 0.757, test acc 0.757, time 298.6 sec\n",
      "epoch 4, loss 0.6263, train acc 0.757, test acc 0.759, time 301.1 sec\n",
      "epoch 4, loss 0.6261, train acc 0.757, test acc 0.758, time 303.6 sec\n",
      "epoch 4, loss 0.6257, train acc 0.757, test acc 0.759, time 306.2 sec\n",
      "epoch 4, loss 0.6259, train acc 0.757, test acc 0.760, time 308.9 sec\n",
      "epoch 4, loss 0.6252, train acc 0.757, test acc 0.761, time 311.4 sec\n",
      "epoch 4, loss 0.6251, train acc 0.757, test acc 0.763, time 314.0 sec\n",
      "epoch 4, loss 0.6244, train acc 0.757, test acc 0.765, time 316.7 sec\n",
      "epoch 4, loss 0.6241, train acc 0.757, test acc 0.765, time 319.2 sec\n",
      "epoch 4, loss 0.6239, train acc 0.758, test acc 0.765, time 321.8 sec\n",
      "epoch 4, loss 0.6237, train acc 0.757, test acc 0.766, time 324.3 sec\n",
      "epoch 4, loss 0.6240, train acc 0.758, test acc 0.767, time 326.8 sec\n",
      "epoch 4, loss 0.6238, train acc 0.758, test acc 0.769, time 329.3 sec\n",
      "epoch 4, loss 0.6239, train acc 0.758, test acc 0.767, time 331.9 sec\n",
      "epoch 4, loss 0.6241, train acc 0.758, test acc 0.766, time 334.4 sec\n",
      "epoch 4, loss 0.6236, train acc 0.758, test acc 0.765, time 336.9 sec\n",
      "epoch 4, loss 0.6240, train acc 0.758, test acc 0.764, time 339.4 sec\n",
      "epoch 4, loss 0.6243, train acc 0.758, test acc 0.764, time 341.9 sec\n",
      "epoch 4, loss 0.6242, train acc 0.758, test acc 0.767, time 344.5 sec\n",
      "epoch 4, loss 0.6238, train acc 0.758, test acc 0.765, time 347.0 sec\n",
      "epoch 4, loss 0.6233, train acc 0.758, test acc 0.764, time 349.5 sec\n",
      "epoch 4, loss 0.6226, train acc 0.758, test acc 0.761, time 352.0 sec\n",
      "epoch 4, loss 0.6226, train acc 0.758, test acc 0.760, time 354.5 sec\n",
      "epoch 4, loss 0.6228, train acc 0.758, test acc 0.757, time 357.1 sec\n",
      "epoch 4, loss 0.6228, train acc 0.758, test acc 0.758, time 359.6 sec\n",
      "epoch 4, loss 0.6221, train acc 0.758, test acc 0.758, time 362.1 sec\n",
      "epoch 4, loss 0.6226, train acc 0.758, test acc 0.759, time 364.6 sec\n",
      "epoch 4, loss 0.6222, train acc 0.759, test acc 0.760, time 367.1 sec\n",
      "epoch 4, loss 0.6215, train acc 0.759, test acc 0.764, time 369.6 sec\n",
      "epoch 4, loss 0.6206, train acc 0.759, test acc 0.765, time 372.2 sec\n",
      "epoch 4, loss 0.6209, train acc 0.759, test acc 0.761, time 374.8 sec\n",
      "epoch 4, loss 0.6203, train acc 0.759, test acc 0.765, time 377.3 sec\n",
      "epoch 4, loss 0.6204, train acc 0.759, test acc 0.766, time 380.3 sec\n",
      "epoch 4, loss 0.6201, train acc 0.759, test acc 0.766, time 382.9 sec\n",
      "epoch 4, loss 0.6204, train acc 0.759, test acc 0.764, time 385.4 sec\n",
      "epoch 4, loss 0.6201, train acc 0.759, test acc 0.763, time 388.0 sec\n",
      "epoch 4, loss 0.6202, train acc 0.759, test acc 0.760, time 390.5 sec\n",
      "epoch 4, loss 0.6197, train acc 0.760, test acc 0.758, time 393.0 sec\n",
      "epoch 4, loss 0.6192, train acc 0.760, test acc 0.757, time 395.5 sec\n",
      "epoch 4, loss 0.6190, train acc 0.760, test acc 0.756, time 398.1 sec\n",
      "epoch 4, loss 0.6194, train acc 0.760, test acc 0.758, time 400.6 sec\n",
      "epoch 4, loss 0.6192, train acc 0.759, test acc 0.760, time 403.2 sec\n",
      "epoch 4, loss 0.6190, train acc 0.760, test acc 0.762, time 405.7 sec\n",
      "epoch 4, loss 0.6191, train acc 0.760, test acc 0.765, time 408.2 sec\n",
      "epoch 4, loss 0.6187, train acc 0.760, test acc 0.767, time 410.7 sec\n",
      "epoch 4, loss 0.6186, train acc 0.760, test acc 0.767, time 413.2 sec\n",
      "epoch 4, loss 0.6186, train acc 0.760, test acc 0.769, time 415.8 sec\n",
      "epoch 4, loss 0.6182, train acc 0.760, test acc 0.768, time 418.4 sec\n",
      "epoch 4, loss 0.6180, train acc 0.760, test acc 0.767, time 420.9 sec\n",
      "epoch 4, loss 0.6172, train acc 0.760, test acc 0.766, time 423.4 sec\n",
      "epoch 4, loss 0.6174, train acc 0.760, test acc 0.764, time 426.0 sec\n",
      "epoch 4, loss 0.6175, train acc 0.760, test acc 0.762, time 428.6 sec\n",
      "epoch 4, loss 0.6177, train acc 0.760, test acc 0.765, time 431.1 sec\n",
      "epoch 4, loss 0.6175, train acc 0.760, test acc 0.764, time 433.7 sec\n",
      "epoch 4, loss 0.6170, train acc 0.760, test acc 0.761, time 436.3 sec\n",
      "epoch 4, loss 0.6171, train acc 0.760, test acc 0.755, time 438.8 sec\n",
      "epoch 4, loss 0.6168, train acc 0.760, test acc 0.751, time 441.4 sec\n",
      "epoch 4, loss 0.6164, train acc 0.761, test acc 0.753, time 443.9 sec\n",
      "epoch 4, loss 0.6161, train acc 0.761, test acc 0.756, time 446.4 sec\n",
      "epoch 4, loss 0.6163, train acc 0.761, test acc 0.765, time 449.0 sec\n",
      "epoch 4, loss 0.6160, train acc 0.761, test acc 0.767, time 451.5 sec\n",
      "epoch 4, loss 0.6157, train acc 0.761, test acc 0.765, time 454.0 sec\n",
      "epoch 4, loss 0.6160, train acc 0.761, test acc 0.759, time 456.6 sec\n",
      "epoch 4, loss 0.6157, train acc 0.761, test acc 0.757, time 459.1 sec\n",
      "epoch 4, loss 0.6159, train acc 0.761, test acc 0.759, time 461.6 sec\n",
      "epoch 4, loss 0.6158, train acc 0.761, test acc 0.762, time 464.1 sec\n",
      "epoch 4, loss 0.6160, train acc 0.761, test acc 0.763, time 466.7 sec\n",
      "epoch 4, loss 0.6155, train acc 0.761, test acc 0.764, time 469.2 sec\n",
      "epoch 4, loss 0.6155, train acc 0.761, test acc 0.762, time 471.8 sec\n",
      "epoch 4, loss 0.6153, train acc 0.761, test acc 0.759, time 474.3 sec\n",
      "epoch 4, loss 0.6151, train acc 0.761, test acc 0.758, time 476.8 sec\n",
      "epoch 4, loss 0.6149, train acc 0.761, test acc 0.759, time 479.3 sec\n",
      "epoch 4, loss 0.6149, train acc 0.761, test acc 0.760, time 481.9 sec\n",
      "epoch 4, loss 0.6150, train acc 0.761, test acc 0.763, time 484.4 sec\n",
      "epoch 4, loss 0.6147, train acc 0.761, test acc 0.764, time 486.9 sec\n",
      "epoch 4, loss 0.6144, train acc 0.761, test acc 0.764, time 489.5 sec\n",
      "epoch 4, loss 0.6139, train acc 0.761, test acc 0.765, time 492.0 sec\n",
      "epoch 4, loss 0.6140, train acc 0.761, test acc 0.768, time 494.6 sec\n",
      "epoch 4, loss 0.6137, train acc 0.761, test acc 0.769, time 497.1 sec\n",
      "epoch 4, loss 0.6135, train acc 0.761, test acc 0.770, time 499.7 sec\n",
      "epoch 4, loss 0.6131, train acc 0.762, test acc 0.771, time 502.2 sec\n",
      "epoch 4, loss 0.6131, train acc 0.762, test acc 0.769, time 504.7 sec\n",
      "epoch 4, loss 0.6132, train acc 0.762, test acc 0.767, time 507.3 sec\n",
      "epoch 4, loss 0.6131, train acc 0.762, test acc 0.767, time 509.8 sec\n",
      "epoch 4, loss 0.6129, train acc 0.762, test acc 0.765, time 512.5 sec\n",
      "epoch 4, loss 0.6127, train acc 0.762, test acc 0.765, time 515.0 sec\n",
      "epoch 4, loss 0.6125, train acc 0.762, test acc 0.766, time 517.5 sec\n",
      "epoch 4, loss 0.6123, train acc 0.762, test acc 0.768, time 520.0 sec\n",
      "epoch 4, loss 0.6119, train acc 0.762, test acc 0.765, time 522.6 sec\n",
      "epoch 4, loss 0.6117, train acc 0.762, test acc 0.764, time 525.2 sec\n",
      "epoch 4, loss 0.6115, train acc 0.762, test acc 0.766, time 527.7 sec\n",
      "epoch 4, loss 0.6113, train acc 0.762, test acc 0.768, time 530.2 sec\n",
      "epoch 4, loss 0.6117, train acc 0.762, test acc 0.768, time 532.7 sec\n",
      "epoch 4, loss 0.6120, train acc 0.762, test acc 0.768, time 535.3 sec\n",
      "epoch 4, loss 0.6123, train acc 0.762, test acc 0.768, time 537.8 sec\n",
      "epoch 4, loss 0.6121, train acc 0.762, test acc 0.770, time 540.4 sec\n",
      "epoch 4, loss 0.6117, train acc 0.762, test acc 0.774, time 542.9 sec\n",
      "epoch 4, loss 0.6114, train acc 0.762, test acc 0.775, time 545.5 sec\n",
      "epoch 4, loss 0.6116, train acc 0.762, test acc 0.775, time 548.1 sec\n",
      "epoch 4, loss 0.6113, train acc 0.762, test acc 0.774, time 550.6 sec\n",
      "epoch 4, loss 0.6109, train acc 0.762, test acc 0.772, time 553.1 sec\n",
      "epoch 4, loss 0.6104, train acc 0.763, test acc 0.771, time 555.7 sec\n",
      "epoch 4, loss 0.6104, train acc 0.763, test acc 0.772, time 558.2 sec\n",
      "epoch 4, loss 0.6102, train acc 0.763, test acc 0.771, time 560.9 sec\n",
      "epoch 4, loss 0.6098, train acc 0.763, test acc 0.771, time 563.4 sec\n",
      "epoch 4, loss 0.6093, train acc 0.763, test acc 0.771, time 566.0 sec\n",
      "epoch 4, loss 0.6089, train acc 0.764, test acc 0.774, time 568.5 sec\n",
      "epoch 4, loss 0.6085, train acc 0.764, test acc 0.774, time 571.0 sec\n",
      "epoch 4, loss 0.6086, train acc 0.764, test acc 0.772, time 573.6 sec\n",
      "epoch 4, loss 0.6087, train acc 0.764, test acc 0.773, time 576.1 sec\n",
      "epoch 4, loss 0.6085, train acc 0.764, test acc 0.774, time 578.6 sec\n",
      "epoch 4, loss 0.6082, train acc 0.764, test acc 0.773, time 581.1 sec\n",
      "epoch 4, loss 0.6082, train acc 0.764, test acc 0.774, time 583.6 sec\n",
      "epoch 4, loss 0.6079, train acc 0.764, test acc 0.773, time 586.2 sec\n",
      "epoch 4, loss 0.6074, train acc 0.764, test acc 0.771, time 588.7 sec\n",
      "epoch 4, loss 0.6068, train acc 0.765, test acc 0.766, time 591.2 sec\n",
      "epoch 4, loss 0.6064, train acc 0.765, test acc 0.764, time 593.7 sec\n",
      "epoch 4, loss 0.6067, train acc 0.765, test acc 0.766, time 596.2 sec\n",
      "epoch 5, loss 0.6223, train acc 0.773, test acc 0.773, time 2.5 sec\n",
      "epoch 5, loss 0.5789, train acc 0.799, test acc 0.775, time 5.0 sec\n",
      "epoch 5, loss 0.5550, train acc 0.809, test acc 0.775, time 7.5 sec\n",
      "epoch 5, loss 0.5330, train acc 0.808, test acc 0.773, time 10.1 sec\n",
      "epoch 5, loss 0.5337, train acc 0.803, test acc 0.768, time 12.6 sec\n",
      "epoch 5, loss 0.5474, train acc 0.796, test acc 0.766, time 15.1 sec\n",
      "epoch 5, loss 0.5501, train acc 0.793, test acc 0.768, time 17.7 sec\n",
      "epoch 5, loss 0.5601, train acc 0.789, test acc 0.768, time 20.3 sec\n",
      "epoch 5, loss 0.5597, train acc 0.786, test acc 0.771, time 22.7 sec\n",
      "epoch 5, loss 0.5607, train acc 0.784, test acc 0.772, time 25.3 sec\n",
      "epoch 5, loss 0.5646, train acc 0.781, test acc 0.771, time 27.7 sec\n",
      "epoch 5, loss 0.5667, train acc 0.779, test acc 0.771, time 30.3 sec\n",
      "epoch 5, loss 0.5711, train acc 0.777, test acc 0.773, time 32.8 sec\n",
      "epoch 5, loss 0.5753, train acc 0.776, test acc 0.773, time 35.3 sec\n",
      "epoch 5, loss 0.5729, train acc 0.778, test acc 0.776, time 37.8 sec\n",
      "epoch 5, loss 0.5702, train acc 0.779, test acc 0.776, time 40.3 sec\n",
      "epoch 5, loss 0.5711, train acc 0.778, test acc 0.771, time 42.9 sec\n",
      "epoch 5, loss 0.5729, train acc 0.777, test acc 0.768, time 45.4 sec\n",
      "epoch 5, loss 0.5736, train acc 0.779, test acc 0.765, time 47.9 sec\n",
      "epoch 5, loss 0.5735, train acc 0.779, test acc 0.761, time 50.4 sec\n",
      "epoch 5, loss 0.5706, train acc 0.780, test acc 0.757, time 52.9 sec\n",
      "epoch 5, loss 0.5679, train acc 0.781, test acc 0.757, time 55.5 sec\n",
      "epoch 5, loss 0.5659, train acc 0.782, test acc 0.759, time 58.0 sec\n",
      "epoch 5, loss 0.5675, train acc 0.781, test acc 0.759, time 60.5 sec\n",
      "epoch 5, loss 0.5685, train acc 0.780, test acc 0.763, time 63.0 sec\n",
      "epoch 5, loss 0.5697, train acc 0.780, test acc 0.766, time 65.5 sec\n",
      "epoch 5, loss 0.5694, train acc 0.780, test acc 0.769, time 68.1 sec\n",
      "epoch 5, loss 0.5648, train acc 0.781, test acc 0.775, time 70.7 sec\n",
      "epoch 5, loss 0.5621, train acc 0.782, test acc 0.778, time 73.2 sec\n",
      "epoch 5, loss 0.5602, train acc 0.783, test acc 0.781, time 75.8 sec\n",
      "epoch 5, loss 0.5626, train acc 0.783, test acc 0.780, time 78.3 sec\n",
      "epoch 5, loss 0.5616, train acc 0.784, test acc 0.779, time 80.8 sec\n",
      "epoch 5, loss 0.5608, train acc 0.785, test acc 0.779, time 83.4 sec\n",
      "epoch 5, loss 0.5628, train acc 0.784, test acc 0.775, time 85.9 sec\n",
      "epoch 5, loss 0.5616, train acc 0.784, test acc 0.776, time 88.4 sec\n",
      "epoch 5, loss 0.5623, train acc 0.784, test acc 0.773, time 90.9 sec\n",
      "epoch 5, loss 0.5603, train acc 0.785, test acc 0.769, time 93.4 sec\n",
      "epoch 5, loss 0.5593, train acc 0.784, test acc 0.766, time 96.0 sec\n",
      "epoch 5, loss 0.5587, train acc 0.784, test acc 0.765, time 98.5 sec\n",
      "epoch 5, loss 0.5591, train acc 0.784, test acc 0.764, time 101.0 sec\n",
      "epoch 5, loss 0.5625, train acc 0.782, test acc 0.766, time 103.5 sec\n",
      "epoch 5, loss 0.5617, train acc 0.782, test acc 0.766, time 106.0 sec\n",
      "epoch 5, loss 0.5643, train acc 0.781, test acc 0.768, time 108.6 sec\n",
      "epoch 5, loss 0.5643, train acc 0.780, test acc 0.772, time 111.1 sec\n",
      "epoch 5, loss 0.5642, train acc 0.780, test acc 0.777, time 113.6 sec\n",
      "epoch 5, loss 0.5643, train acc 0.780, test acc 0.780, time 116.2 sec\n",
      "epoch 5, loss 0.5648, train acc 0.780, test acc 0.779, time 118.7 sec\n",
      "epoch 5, loss 0.5663, train acc 0.780, test acc 0.780, time 121.3 sec\n",
      "epoch 5, loss 0.5650, train acc 0.781, test acc 0.783, time 123.8 sec\n",
      "epoch 5, loss 0.5662, train acc 0.780, test acc 0.779, time 126.3 sec\n",
      "epoch 5, loss 0.5657, train acc 0.781, test acc 0.779, time 128.8 sec\n",
      "epoch 5, loss 0.5662, train acc 0.781, test acc 0.778, time 131.3 sec\n",
      "epoch 5, loss 0.5666, train acc 0.781, test acc 0.774, time 133.9 sec\n",
      "epoch 5, loss 0.5697, train acc 0.780, test acc 0.775, time 136.5 sec\n",
      "epoch 5, loss 0.5707, train acc 0.779, test acc 0.775, time 139.0 sec\n",
      "epoch 5, loss 0.5704, train acc 0.779, test acc 0.773, time 141.5 sec\n",
      "epoch 5, loss 0.5711, train acc 0.779, test acc 0.774, time 144.0 sec\n",
      "epoch 5, loss 0.5713, train acc 0.779, test acc 0.775, time 146.6 sec\n",
      "epoch 5, loss 0.5726, train acc 0.778, test acc 0.778, time 149.1 sec\n",
      "epoch 5, loss 0.5718, train acc 0.779, test acc 0.776, time 151.6 sec\n",
      "epoch 5, loss 0.5720, train acc 0.778, test acc 0.774, time 154.1 sec\n",
      "epoch 5, loss 0.5733, train acc 0.778, test acc 0.774, time 156.6 sec\n",
      "epoch 5, loss 0.5729, train acc 0.779, test acc 0.774, time 159.1 sec\n",
      "epoch 5, loss 0.5724, train acc 0.779, test acc 0.777, time 161.7 sec\n",
      "epoch 5, loss 0.5735, train acc 0.778, test acc 0.782, time 164.2 sec\n",
      "epoch 5, loss 0.5723, train acc 0.779, test acc 0.784, time 166.7 sec\n",
      "epoch 5, loss 0.5736, train acc 0.779, test acc 0.781, time 169.2 sec\n",
      "epoch 5, loss 0.5725, train acc 0.780, test acc 0.781, time 171.7 sec\n",
      "epoch 5, loss 0.5731, train acc 0.780, test acc 0.782, time 174.3 sec\n",
      "epoch 5, loss 0.5730, train acc 0.780, test acc 0.780, time 176.8 sec\n",
      "epoch 5, loss 0.5723, train acc 0.780, test acc 0.778, time 179.3 sec\n",
      "epoch 5, loss 0.5723, train acc 0.780, test acc 0.779, time 181.8 sec\n",
      "epoch 5, loss 0.5721, train acc 0.780, test acc 0.778, time 184.3 sec\n",
      "epoch 5, loss 0.5718, train acc 0.780, test acc 0.777, time 186.8 sec\n",
      "epoch 5, loss 0.5722, train acc 0.780, test acc 0.779, time 189.5 sec\n",
      "epoch 5, loss 0.5720, train acc 0.779, test acc 0.780, time 192.1 sec\n",
      "epoch 5, loss 0.5709, train acc 0.780, test acc 0.780, time 194.6 sec\n",
      "epoch 5, loss 0.5694, train acc 0.781, test acc 0.780, time 197.1 sec\n",
      "epoch 5, loss 0.5682, train acc 0.781, test acc 0.778, time 199.7 sec\n",
      "epoch 5, loss 0.5682, train acc 0.781, test acc 0.778, time 202.3 sec\n",
      "epoch 5, loss 0.5690, train acc 0.780, test acc 0.778, time 204.8 sec\n",
      "epoch 5, loss 0.5692, train acc 0.780, test acc 0.781, time 207.3 sec\n",
      "epoch 5, loss 0.5696, train acc 0.780, test acc 0.783, time 209.8 sec\n",
      "epoch 5, loss 0.5683, train acc 0.780, test acc 0.781, time 212.3 sec\n",
      "epoch 5, loss 0.5676, train acc 0.781, test acc 0.782, time 214.9 sec\n",
      "epoch 5, loss 0.5676, train acc 0.781, test acc 0.783, time 217.4 sec\n",
      "epoch 5, loss 0.5683, train acc 0.781, test acc 0.786, time 219.9 sec\n",
      "epoch 5, loss 0.5683, train acc 0.781, test acc 0.785, time 222.4 sec\n",
      "epoch 5, loss 0.5679, train acc 0.781, test acc 0.777, time 224.9 sec\n",
      "epoch 5, loss 0.5679, train acc 0.781, test acc 0.776, time 227.5 sec\n",
      "epoch 5, loss 0.5675, train acc 0.782, test acc 0.778, time 230.0 sec\n",
      "epoch 5, loss 0.5674, train acc 0.782, test acc 0.777, time 232.5 sec\n",
      "epoch 5, loss 0.5662, train acc 0.782, test acc 0.774, time 235.0 sec\n",
      "epoch 5, loss 0.5661, train acc 0.782, test acc 0.771, time 237.5 sec\n",
      "epoch 5, loss 0.5665, train acc 0.782, test acc 0.771, time 240.1 sec\n",
      "epoch 5, loss 0.5667, train acc 0.782, test acc 0.775, time 242.7 sec\n",
      "epoch 5, loss 0.5664, train acc 0.782, test acc 0.777, time 245.2 sec\n",
      "epoch 5, loss 0.5661, train acc 0.783, test acc 0.783, time 247.7 sec\n",
      "epoch 5, loss 0.5658, train acc 0.783, test acc 0.783, time 250.2 sec\n",
      "epoch 5, loss 0.5657, train acc 0.783, test acc 0.782, time 252.8 sec\n",
      "epoch 5, loss 0.5668, train acc 0.783, test acc 0.784, time 255.4 sec\n",
      "epoch 5, loss 0.5667, train acc 0.783, test acc 0.785, time 257.9 sec\n",
      "epoch 5, loss 0.5670, train acc 0.783, test acc 0.783, time 260.4 sec\n",
      "epoch 5, loss 0.5677, train acc 0.782, test acc 0.783, time 262.9 sec\n",
      "epoch 5, loss 0.5672, train acc 0.783, test acc 0.782, time 265.5 sec\n",
      "epoch 5, loss 0.5668, train acc 0.783, test acc 0.780, time 268.0 sec\n",
      "epoch 5, loss 0.5681, train acc 0.782, test acc 0.784, time 270.5 sec\n",
      "epoch 5, loss 0.5676, train acc 0.782, test acc 0.783, time 273.0 sec\n",
      "epoch 5, loss 0.5686, train acc 0.782, test acc 0.781, time 275.5 sec\n",
      "epoch 5, loss 0.5686, train acc 0.782, test acc 0.782, time 278.0 sec\n",
      "epoch 5, loss 0.5684, train acc 0.782, test acc 0.782, time 280.6 sec\n",
      "epoch 5, loss 0.5683, train acc 0.782, test acc 0.784, time 283.1 sec\n",
      "epoch 5, loss 0.5689, train acc 0.781, test acc 0.784, time 285.6 sec\n",
      "epoch 5, loss 0.5688, train acc 0.782, test acc 0.783, time 288.1 sec\n",
      "epoch 5, loss 0.5685, train acc 0.781, test acc 0.782, time 290.6 sec\n",
      "epoch 5, loss 0.5683, train acc 0.782, test acc 0.783, time 293.2 sec\n",
      "epoch 5, loss 0.5682, train acc 0.782, test acc 0.786, time 295.7 sec\n",
      "epoch 5, loss 0.5684, train acc 0.782, test acc 0.787, time 298.2 sec\n",
      "epoch 5, loss 0.5679, train acc 0.782, test acc 0.786, time 300.8 sec\n",
      "epoch 5, loss 0.5678, train acc 0.782, test acc 0.780, time 303.4 sec\n",
      "epoch 5, loss 0.5676, train acc 0.782, test acc 0.778, time 306.8 sec\n",
      "epoch 5, loss 0.5685, train acc 0.782, test acc 0.787, time 309.5 sec\n",
      "epoch 5, loss 0.5678, train acc 0.782, test acc 0.785, time 312.0 sec\n",
      "epoch 5, loss 0.5678, train acc 0.782, test acc 0.778, time 314.6 sec\n",
      "epoch 5, loss 0.5683, train acc 0.782, test acc 0.773, time 317.1 sec\n",
      "epoch 5, loss 0.5683, train acc 0.782, test acc 0.772, time 319.7 sec\n",
      "epoch 5, loss 0.5685, train acc 0.782, test acc 0.778, time 322.2 sec\n",
      "epoch 5, loss 0.5680, train acc 0.783, test acc 0.784, time 324.8 sec\n",
      "epoch 5, loss 0.5678, train acc 0.783, test acc 0.787, time 327.3 sec\n",
      "epoch 5, loss 0.5681, train acc 0.783, test acc 0.788, time 329.8 sec\n",
      "epoch 5, loss 0.5674, train acc 0.783, test acc 0.781, time 332.4 sec\n",
      "epoch 5, loss 0.5667, train acc 0.784, test acc 0.783, time 334.9 sec\n",
      "epoch 5, loss 0.5662, train acc 0.784, test acc 0.785, time 337.4 sec\n",
      "epoch 5, loss 0.5664, train acc 0.784, test acc 0.780, time 339.9 sec\n",
      "epoch 5, loss 0.5658, train acc 0.784, test acc 0.773, time 342.5 sec\n",
      "epoch 5, loss 0.5656, train acc 0.784, test acc 0.767, time 345.0 sec\n",
      "epoch 5, loss 0.5653, train acc 0.784, test acc 0.766, time 347.6 sec\n",
      "epoch 5, loss 0.5650, train acc 0.784, test acc 0.771, time 350.2 sec\n",
      "epoch 5, loss 0.5654, train acc 0.784, test acc 0.778, time 352.7 sec\n",
      "epoch 5, loss 0.5652, train acc 0.784, test acc 0.784, time 355.2 sec\n",
      "epoch 5, loss 0.5653, train acc 0.784, test acc 0.785, time 357.7 sec\n",
      "epoch 5, loss 0.5646, train acc 0.785, test acc 0.786, time 360.5 sec\n",
      "epoch 5, loss 0.5644, train acc 0.785, test acc 0.786, time 363.0 sec\n",
      "epoch 5, loss 0.5639, train acc 0.785, test acc 0.787, time 365.6 sec\n",
      "epoch 5, loss 0.5635, train acc 0.785, test acc 0.787, time 368.3 sec\n",
      "epoch 5, loss 0.5636, train acc 0.785, test acc 0.785, time 370.8 sec\n",
      "epoch 5, loss 0.5635, train acc 0.785, test acc 0.783, time 373.5 sec\n",
      "epoch 5, loss 0.5635, train acc 0.785, test acc 0.783, time 376.0 sec\n",
      "epoch 5, loss 0.5634, train acc 0.785, test acc 0.784, time 378.6 sec\n",
      "epoch 5, loss 0.5632, train acc 0.786, test acc 0.787, time 381.1 sec\n",
      "epoch 5, loss 0.5629, train acc 0.786, test acc 0.789, time 383.6 sec\n",
      "epoch 5, loss 0.5631, train acc 0.786, test acc 0.791, time 386.2 sec\n",
      "epoch 5, loss 0.5624, train acc 0.786, test acc 0.788, time 388.8 sec\n",
      "epoch 5, loss 0.5621, train acc 0.786, test acc 0.785, time 391.3 sec\n",
      "epoch 5, loss 0.5621, train acc 0.786, test acc 0.781, time 393.9 sec\n",
      "epoch 5, loss 0.5625, train acc 0.786, test acc 0.781, time 396.4 sec\n",
      "epoch 5, loss 0.5625, train acc 0.786, test acc 0.783, time 398.9 sec\n",
      "epoch 5, loss 0.5624, train acc 0.786, test acc 0.784, time 401.5 sec\n",
      "epoch 5, loss 0.5618, train acc 0.786, test acc 0.788, time 404.0 sec\n",
      "epoch 5, loss 0.5611, train acc 0.786, test acc 0.787, time 406.7 sec\n",
      "epoch 5, loss 0.5607, train acc 0.787, test acc 0.788, time 409.3 sec\n",
      "epoch 5, loss 0.5610, train acc 0.786, test acc 0.789, time 411.9 sec\n",
      "epoch 5, loss 0.5613, train acc 0.786, test acc 0.785, time 414.5 sec\n",
      "epoch 5, loss 0.5614, train acc 0.786, test acc 0.782, time 417.0 sec\n",
      "epoch 5, loss 0.5611, train acc 0.786, test acc 0.783, time 419.6 sec\n",
      "epoch 5, loss 0.5611, train acc 0.786, test acc 0.783, time 422.2 sec\n",
      "epoch 5, loss 0.5610, train acc 0.787, test acc 0.787, time 424.8 sec\n",
      "epoch 5, loss 0.5605, train acc 0.787, test acc 0.790, time 427.4 sec\n",
      "epoch 5, loss 0.5598, train acc 0.787, test acc 0.790, time 430.2 sec\n",
      "epoch 5, loss 0.5597, train acc 0.787, test acc 0.787, time 432.8 sec\n",
      "epoch 5, loss 0.5604, train acc 0.787, test acc 0.784, time 435.4 sec\n",
      "epoch 5, loss 0.5603, train acc 0.787, test acc 0.782, time 438.0 sec\n",
      "epoch 5, loss 0.5606, train acc 0.787, test acc 0.779, time 440.7 sec\n",
      "epoch 5, loss 0.5608, train acc 0.787, test acc 0.781, time 443.3 sec\n",
      "epoch 5, loss 0.5606, train acc 0.787, test acc 0.784, time 445.8 sec\n",
      "epoch 5, loss 0.5600, train acc 0.787, test acc 0.784, time 448.3 sec\n",
      "epoch 5, loss 0.5600, train acc 0.787, test acc 0.785, time 450.9 sec\n",
      "epoch 5, loss 0.5599, train acc 0.787, test acc 0.783, time 453.4 sec\n",
      "epoch 5, loss 0.5597, train acc 0.787, test acc 0.784, time 455.9 sec\n",
      "epoch 5, loss 0.5598, train acc 0.786, test acc 0.787, time 458.5 sec\n",
      "epoch 5, loss 0.5602, train acc 0.786, test acc 0.788, time 461.0 sec\n",
      "epoch 5, loss 0.5596, train acc 0.786, test acc 0.786, time 463.6 sec\n",
      "epoch 5, loss 0.5593, train acc 0.786, test acc 0.785, time 466.1 sec\n",
      "epoch 5, loss 0.5591, train acc 0.787, test acc 0.786, time 468.6 sec\n",
      "epoch 5, loss 0.5591, train acc 0.787, test acc 0.787, time 471.1 sec\n",
      "epoch 5, loss 0.5593, train acc 0.787, test acc 0.788, time 473.7 sec\n",
      "epoch 5, loss 0.5588, train acc 0.787, test acc 0.789, time 476.3 sec\n",
      "epoch 5, loss 0.5587, train acc 0.787, test acc 0.788, time 478.8 sec\n",
      "epoch 5, loss 0.5591, train acc 0.787, test acc 0.787, time 481.3 sec\n",
      "epoch 5, loss 0.5592, train acc 0.787, test acc 0.787, time 483.8 sec\n",
      "epoch 5, loss 0.5589, train acc 0.787, test acc 0.786, time 486.3 sec\n",
      "epoch 5, loss 0.5585, train acc 0.787, test acc 0.786, time 488.9 sec\n",
      "epoch 5, loss 0.5586, train acc 0.787, test acc 0.790, time 491.4 sec\n",
      "epoch 5, loss 0.5581, train acc 0.787, test acc 0.793, time 493.9 sec\n",
      "epoch 5, loss 0.5577, train acc 0.787, test acc 0.795, time 496.5 sec\n",
      "epoch 5, loss 0.5578, train acc 0.787, test acc 0.792, time 499.0 sec\n",
      "epoch 5, loss 0.5576, train acc 0.787, test acc 0.791, time 501.5 sec\n",
      "epoch 5, loss 0.5572, train acc 0.787, test acc 0.788, time 504.1 sec\n",
      "epoch 5, loss 0.5573, train acc 0.788, test acc 0.784, time 506.6 sec\n",
      "epoch 5, loss 0.5575, train acc 0.788, test acc 0.784, time 509.1 sec\n",
      "epoch 5, loss 0.5570, train acc 0.788, test acc 0.786, time 511.6 sec\n",
      "epoch 5, loss 0.5568, train acc 0.788, test acc 0.786, time 514.2 sec\n",
      "epoch 5, loss 0.5565, train acc 0.788, test acc 0.789, time 516.8 sec\n",
      "epoch 5, loss 0.5563, train acc 0.788, test acc 0.791, time 519.3 sec\n",
      "epoch 5, loss 0.5563, train acc 0.788, test acc 0.793, time 521.9 sec\n",
      "epoch 5, loss 0.5562, train acc 0.788, test acc 0.791, time 524.4 sec\n",
      "epoch 5, loss 0.5561, train acc 0.788, test acc 0.790, time 527.0 sec\n",
      "epoch 5, loss 0.5561, train acc 0.788, test acc 0.789, time 529.5 sec\n",
      "epoch 5, loss 0.5557, train acc 0.788, test acc 0.790, time 532.0 sec\n",
      "epoch 5, loss 0.5557, train acc 0.788, test acc 0.791, time 534.5 sec\n",
      "epoch 5, loss 0.5555, train acc 0.788, test acc 0.791, time 537.0 sec\n",
      "epoch 5, loss 0.5556, train acc 0.788, test acc 0.786, time 539.5 sec\n",
      "epoch 5, loss 0.5559, train acc 0.788, test acc 0.784, time 542.1 sec\n",
      "epoch 5, loss 0.5559, train acc 0.788, test acc 0.780, time 544.6 sec\n",
      "epoch 5, loss 0.5557, train acc 0.788, test acc 0.779, time 547.2 sec\n",
      "epoch 5, loss 0.5558, train acc 0.788, test acc 0.778, time 549.8 sec\n",
      "epoch 5, loss 0.5561, train acc 0.788, test acc 0.780, time 552.4 sec\n",
      "epoch 5, loss 0.5558, train acc 0.788, test acc 0.780, time 554.9 sec\n",
      "epoch 5, loss 0.5559, train acc 0.788, test acc 0.780, time 557.5 sec\n",
      "epoch 5, loss 0.5560, train acc 0.788, test acc 0.780, time 560.0 sec\n",
      "epoch 5, loss 0.5560, train acc 0.788, test acc 0.781, time 562.5 sec\n",
      "epoch 5, loss 0.5560, train acc 0.788, test acc 0.785, time 565.0 sec\n",
      "epoch 5, loss 0.5558, train acc 0.789, test acc 0.784, time 567.6 sec\n",
      "epoch 5, loss 0.5559, train acc 0.789, test acc 0.784, time 570.1 sec\n",
      "epoch 5, loss 0.5557, train acc 0.789, test acc 0.784, time 572.7 sec\n",
      "epoch 5, loss 0.5556, train acc 0.789, test acc 0.785, time 575.2 sec\n",
      "epoch 5, loss 0.5554, train acc 0.789, test acc 0.787, time 577.7 sec\n",
      "epoch 5, loss 0.5549, train acc 0.789, test acc 0.781, time 580.3 sec\n",
      "epoch 5, loss 0.5548, train acc 0.789, test acc 0.779, time 582.8 sec\n",
      "epoch 5, loss 0.5546, train acc 0.789, test acc 0.783, time 585.3 sec\n",
      "epoch 5, loss 0.5550, train acc 0.789, test acc 0.792, time 587.8 sec\n",
      "epoch 5, loss 0.5551, train acc 0.789, test acc 0.793, time 590.3 sec\n",
      "epoch 5, loss 0.5554, train acc 0.789, test acc 0.793, time 592.9 sec\n",
      "epoch 5, loss 0.5553, train acc 0.789, test acc 0.789, time 595.4 sec\n",
      "epoch 5, loss 0.5549, train acc 0.789, test acc 0.787, time 597.9 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.001, 5\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "train_cnn(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "“MachineLearning”",
   "language": "python",
   "name": "machginelearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
